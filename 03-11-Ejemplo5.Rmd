---
title: "Pernoctaciones en alojamientos turísticos de turistas extranjeros"
subtitle: "Alisado exponencial"
author: "Iván Arribas (Depto. Análisis Económico. Universitat de València)"
output: 
  html_document:
    theme: cerulean
    highlight: pygments 
    fig_caption: false
    df_print: kable
    toc: true
    toc_depth: 2
    number_sections: true
    self_contained: true
    code_download: true
---

```{r chunk_setup, echo = FALSE}
knitr::opts_chunk$set(warning = FALSE, 
                      message = FALSE, 
                      comment = "",
                      fig.align = "center", 
                      fig.show = "hold",
                      fig.height = 4,
                      fig.width = 8,
                      out.width = "80%") 
```

```{r options_setup, echo = FALSE}
options(scipen = 999) #- para quitar la notacion cientifica
```

```{r librerias, echo = FALSE}
library(forecast)
library(ggplot2); theme_set(theme_bw())
library(gridExtra)
library(grid)
```

\
\

# Introducción

Consideremos de nuevo la serie temporal correspondiente al número de pernoctaciones que los turistas extranjeros realizan en España en alojamientos turísticos autorizados (que llamaremos Pernoctaciones en adelante). Esta serie está disponible en Eurostat desde enero de 2000 hasta diciembre de 2019, un total de 20 años y 240 observaciones.

La serie presenta tendencia decreciente hasta finales de la primera década del presente siglo y luego creciente hasta los dos últimos años. La estacionalidad de orden 12 esta determinada por las vacaciones de verano. El esquema es multiplicativo.

```{r}
Pernoctaciones <- read.csv2("./series/Pernoctaciones.csv", header = TRUE)
Pernoctaciones <- ts(Pernoctaciones[,2], start = 2000, frequency = 12)
```

```{r}
autoplot(Pernoctaciones/1000000,
         xlab = "",
         ylab = "Noches (millones)",
         main = "Figura 1. Pernoctaciones (datos mensuales)") +
  scale_x_continuous(breaks= seq(2000, 2020, 2))  
```

La serie de Pernoctaciones anualizada  (y en millones de noches) sería

```{r}
PernoctacionesAnual = aggregate(Pernoctaciones/1000000, FUN = sum)

autoplot(PernoctacionesAnual,
         xlab = "",
         ylab = "Noches (millones)",
         main = "Figura 2. Pernoctaciones") +
  scale_x_continuous(breaks= seq(2000, 2020, 2)) 
```

\
\


# Ajuste por alisado exponencial de las Pernoctaciones anuales

Vamos a aplicar la metodología de alisado exponencial a la serie de pernoctaciones anuales.

```{r}
PernoctacionesAnualEts <- ets(PernoctacionesAnual, model = "ZZZ")
summary(PernoctacionesAnualEts) 
```

Si se estima el modelo sin imponer ninguna restricción, `ets` identifica como modelo óptimo ETS(A,N,N) donde el parámetro $\alpha$ es igual a 1. Es decir, el mejor modelo de alisado corresponde al método ingenuo I con error aditivo: $y_{t+1} = y_t  + \varepsilon_{t+1}$, visto ya en el ejemplo del tema 3. El error porcentual cometido (4.2%) es similar al estimado para el método ingenuo I (4.4%). La diferencia se debe a que $\alpha$ no es exactamente 1.

Para la serie anual, aunque hemos ampliado el menú de métodos, no hemos encontrado ningún método mejor que el más sencillo: predecir repitiendo la última observación.

\
\

# Pernoctaciones mensuales

Vamos ahora a aplicar la metodología de alisado exponencial a la serie mensual de pernoctaciones.

\

## Ajuste por alisado exponencial

Si se estima el modelo sin imponer ninguna restricción, `ets` identifica como modelo óptimo ETS(M,Ad,M).

```{r}
PernoctacionesEts <- ets(Pernoctaciones, model = "ZZZ")
summary(PernoctacionesEts) 
```

El modelo estimado tiene pendiente aditiva con amortiguamiento, estacionalidad multiplicativa y residuo multiplicativo:
$$y_{t+1} = (l_t + \phi b_t) \cdot s_{t+1-m} \cdot (1 + \varepsilon_{t+1}).$$

El valor de $\alpha$ indica que el nivel de la serie ha ido variando lentamente en el tiempo. El valor de $\beta$ es prácticamente nulo, por lo que la pendiente se mantiene sin cambios durante el periodo de análisis. El valor de $\gamma$ tan elevado indica que la componente estacional ha evolucionado con el paso de los años. Por último, $\phi$ toma un valor relativamente bajo así que debemos aceptar que incluir amortiguamiento en el modelo mejora su ajuste a la serie. (Véase figura 3.)

```{r}
autoplot(PernoctacionesEts,
         xlab = "",
         main = "Figura 3. Descomposición para Pernoctaciones")
```

La calidad del ajuste es bastante buena, con un MAPE de 3.2% y un RMSE de 252 mil pernoctaciones (o 190 si usamos el MAE). Además, según el MASE, el modelo de alisado exponencial supone una mejora del 38% respecto del método ingenuo con estacionalidad, que ya usamos para Pernoctaciones y tenía un MAPE del 5.3%. Parece que para la serie mensual el método de Alisado si supone una mejora notable en la calidad del ajuste respecto del método más sencillo.
      
Los últimos valores estimados del nivel y la estacionalidad, que corresponden a diciembre de 2019, nos permiten mostrar gráficamente la componente estacional más reciente (figura 4).

```{r, eval = FALSE}
TT <- nrow(PernoctacionesEts$states)
PernoctacionesEts$states[TT,]
```

```{r, echo = FALSE}
TT <- nrow(PernoctacionesEts$states)
round(PernoctacionesEts$states[TT,],2)
```

```{r}
componenteEstacional <- PernoctacionesEts$states[TT, 14:3]

ggplot() +
  geom_line(aes(x = 1:12, y = componenteEstacional)) + 
  geom_hline(yintercept = 1, colour = "blue", lty = 2) +
  ggtitle("Figura 4. Componente estacional") +
  xlab("") +
  ylab("Efecto estacional") +
  scale_x_continuous(breaks= 1:12, 
                     labels = c("Ene", "Feb", "Mar", "Abr", "May", "Jun", 
                                "Jul", "Ago", "Sep", "Oct", "Nov", "Dic")) 
```

El nivel de las pernoctaciones en diciembre de 2019 (última observación) es de 6.4 millones de noches y la pendiente -2,370.33 noches, prácticamente nula (en comparación con el nivel). El mayor número de pernoctaciones tiene lugar en verano, en los meses de julio y agosto. En concreto, destaca el mes agosto con un incremento del 83% (`s5`) en las pernoctaciones respecto de la media anual. Las pernoctaciones en invierno bajan drásticamente respecto de la media anual, observándose en diciembre un 37% menos de pernoctaciones (`s1`). El efecto estacional estimado por el método de alisado es muy similar al estimado durante la descriptiva de la serie.

\

## Predicción

Si pedimos los valores de predicción y su intervalo de confianza al 95% para los próximos tres años tenemos (numéricamente sólo se muestra el primer año):

```{r,eval=FALSE}
PernoctacionesEtsPre <- forecast(PernoctacionesEts, h = 36, level = 95)
PernoctacionesEtsPre
```

```{r,echo=FALSE}
PernoctacionesEtsPre <- forecast(PernoctacionesEts, h = 36, level = 95)
forecast(PernoctacionesEts, h = 12, level = 95)
```

```{r}
autoplot(PernoctacionesEtsPre,
         xlab = "",
         ylab = "Casos",
         main = "Figura 5. Pernoctaciones (2000-2019) y predicción (2020-2022)",
         PI = FALSE)
```

Las predicciones muestran una suave tendencia decreciente. (Véase figura 5.)

\

## Análisis del error

La  figura 6 muestra el residuo del modelo, estimado aditivamente.

```{r}
error <- residuals(PernoctacionesEts, type = "response")
sderror <- sd(error)

autoplot(error,
         xlab = "",
         ylab = "Error",
         main = "Figura 6. Error + Intervención",
         colour = "black") +
  geom_hline(yintercept = c(-3, -2, 2 ,3)*sderror, 
             colour = c("red", "blue", "blue", "red"), lty = 2) + 
  scale_x_continuous(breaks= seq(2000, 2020, 2)) 
```

Se aprecian dos meses, agosto de 2002 y julio de 2014 en los que el residuo supera las tres desviaciones típicas. Además, otros residuos cercanos a las tres desviaciones típicas son susceptibles de ser considerados intervención: agosto de 2001, abril de 2002 y agosto de 2017. Observa que todos las intervenciones caen en meses vacacionales y cuatro de ellas en verano. 

\

## Validación

Ya hemos visto que el modelo comete un error próximo al 3.2%. Este valor es la estimación del _error en la previsión intra-muestral y a un periodo vista_. A fin de poder estimar mejor la capacidad predictiva del modelo vamos a estimar _el error de previsión extra-muestral según el horizonte temporal_.

Asumimos que se precisan diez años para hacer una buena estimación, $k=120$, y que el horizonte temporal es un año, $h = 12$ meses.
  
```{r}  
k <- 120                 #Minimo numero de datos para estimar
h <- 12                  #Horizonte de las predicicones
TT <- length(Pernoctaciones)  #Longitud serie
s <- TT - k - h          #Total de estimaciones

mapeAlisado <- matrix(NA, s + 1, h)
for (i in 0:s) {
  train.set <- subset(Pernoctaciones, start = i + 1, end = i + k)
  test.set <-  subset(Pernoctaciones, start = i + k + 1, end = i + k + h)
  
  fit <- ets(train.set, model = "MAM", damped = TRUE)
  fcast<-forecast(fit, h = h)
  mapeAlisado[i + 1,] <- 100*abs(test.set - fcast$mean)/test.set
}

errorAlisado <- colMeans(mapeAlisado)
errorAlisado

ggplot() +
  geom_line(aes(x = 1:12, y = errorAlisado)) +
  ggtitle("Figura 7. Error de predicción según horizonte temporal") +
  xlab("Horizonte temporal de predicción") +
  ylab("MAPE") +
  scale_x_continuous(breaks= 1:12)
```

La figura 7 muestra el error de previsión extra-muestral según el horizonte de previsión. Se observa como para horizontes de predicción de uno a nueve meses el error de predicción aumenta según aumenta el horizonte de predicción, pasando del 3.8% para predicciones a un mes vista hasta el 5.8% para predicciones a nueve meses vista.

Sin embargo, para previsiones a más largo plazo el error de predicción decrece, hasta situarse en el 5% en las previsiones a un año vista. Sorprendentemente, a un año vista se produce un salto en el error, que alcanza el 6.7%.


\
\

# Modelos alternativos

¿Podemos reducir el error extra-muestral de previsión si cambiamos las opciones por defecto de `ets` o la serie a analizar? Por ejemplo, ¿mejoramos si aplicamos el método de alisado sobre el logaritmo de la serie o usamos el criterio de minimizar el error de las previsiones a dos meses vista, o trabajamos con las pernoctaciones por día?

La figura 8 muestra el error de previsión extra-muestral según el horizonte de previsión para los siguientes modelos (todos con amortiguamiento):

|**Id**  |**Transformación** |**Modelo** |**Método estimación** |
|:-------|:------------------|:----------|:---------------------|
| 1      |Ninguna            |MAdM        |Máxima verosimilitud  |
| 2      |Ninguna            |MAdM        |Mínimo error en previsiones a 2 periodos vista  |
| 3      |Logaritmo          |AAdA        |Máxima verosimilitud  |
| 4      |Logartimo          |AAdA        |Mínimo error en previsiones a 2 periodos vista  |
| 5      |Pernoctaciones por día |MAdM        |Máxima verosimilitud  |
| 6      |Pernoctaciones por día |MAdM        |Mínimo error en previsiones a 2 periodos vista  |

En concreto los comandos utilizados han sido: 

* Modelo 1: `ets(x, model = "MAM", damped = TRUE)`
* Modelo 2: `ets(x, model = "MAM", damped = TRUE, opt.crit = "amse", nmse = 2)`
* Modelo 3: `ets(x, model = "AAA", lambda = 0, biasadj = TRUE, damped = TRUE)`
* Modelo 4: `ets(x, model = "AAA", lambda = 0, biasadj = TRUE, damped = TRUE,  opt.crit = "amse", nmse = 2)`
* Modelo 5: `ets(x/monthdays(x), model = "MAM", damped = TRUE)`
* Modelo 6: `ets(x/monthdays(x), model = "MAM", damped = TRUE, opt.crit = "amse", nmse = 2)`

\

```{r, echo = FALSE}  
k <- 120                 #Minimo numero de datos para estimar
h <- 12                  #Horizonte de las predicicones
TT <- length(Pernoctaciones)  #Longitud serie
s <- TT - k - h          #Total de estimaciones

mapeAlisado1 <- matrix(NA, s + 1, h)
mapeAlisado2 <- matrix(NA, s + 1, h)
mapeAlisado3 <- matrix(NA, s + 1, h)
mapeAlisado4 <- matrix(NA, s + 1, h)
mapeAlisado5 <- matrix(NA, s + 1, h)
mapeAlisado6 <- matrix(NA, s + 1, h)

for (i in 0:s) {
  train.set <- subset(Pernoctaciones, start = i + 1, end = i + k)
  test.set <-  subset(Pernoctaciones, start = i + k + 1, end = i + k + h)
  
  fit <- ets(train.set, model = "MAM", damped = TRUE)
  fcast<-forecast(fit, h = h)
  mapeAlisado1[i + 1,] <- 100*abs(test.set - fcast$mean)/test.set
  
  fit <- ets(train.set, model = "MAM", damped = TRUE, opt.crit = "amse", nmse = 2)
  fcast<-forecast(fit, h = h)
  mapeAlisado2[i + 1,] <- 100*abs(test.set - fcast$mean)/test.set
  
  fit <- ets(train.set, model = "AAA", lambda = 0, biasadj = TRUE, damped = TRUE)
  fcast<-forecast(fit, h = h, biasadj = TRUE)
  mapeAlisado3[i + 1,] <- 100*abs(test.set - fcast$mean)/test.set
  
  fit <- ets(train.set, model = "AAA", lambda = 0, biasadj = TRUE, damped = TRUE,  opt.crit = "amse", nmse = 2)
  fcast<-forecast(fit, h = h, biasadj = TRUE)
  mapeAlisado4[i + 1,] <- 100*abs(test.set - fcast$mean)/test.set
  
  fit <- ets(train.set/monthdays(train.set), model = "MAM", damped = TRUE)
  fcast<-forecast(fit, h = h)
  mapeAlisado5[i + 1,] <- 100*abs(test.set - fcast$mean * monthdays(fcast$mean))/test.set
  
  fit <- ets(train.set/monthdays(train.set), model = "MAM", damped = TRUE, opt.crit = "amse", nmse = 2)
  fcast<-forecast(fit, h = h)
  mapeAlisado6[i + 1,] <- 100*abs(test.set - fcast$mean * monthdays(fcast$mean))/test.set
}


errorAlisado1 <- colMeans(mapeAlisado1)
errorAlisado2 <- colMeans(mapeAlisado2)
errorAlisado3 <- colMeans(mapeAlisado3)
errorAlisado4 <- colMeans(mapeAlisado4)
errorAlisado5 <- colMeans(mapeAlisado5)
errorAlisado6 <- colMeans(mapeAlisado6)

ggplot() +
  geom_line(aes(x = 1:12, y = errorAlisado1, colour = "Modelo 1")) +
  geom_line(aes(x = 1:12, y = errorAlisado2, colour = "Modelo 2")) + 
  geom_line(aes(x = 1:12, y = errorAlisado3, colour = "Modelo 3")) +
  geom_line(aes(x = 1:12, y = errorAlisado4, colour = "Modelo 4")) +
  geom_line(aes(x = 1:12, y = errorAlisado5, colour = "Modelo 5")) +
  geom_line(aes(x = 1:12, y = errorAlisado6, colour = "Modelo 6")) +
  ggtitle("Figura 8. Errores de previsión extra-muestral. Varios modelos") +
  xlab("") +
  ylab("MAPE") +
  scale_x_continuous(breaks= 1:12) +
  scale_color_discrete(name = "Modelos")
```

De la figura 7 deducimos que aunque todos los métodos resultan razonablemente equivalentes en el largo plazo, en el corto plazo las diferencias pueden ser significativas: la mayor diferencia entre los modelos se da para la previsión a dos y tres meses vista y es de 0.6 puntos porcentuales. Si queremos entrar en matices:

* Globalmente los modelos que ofrecen mejores previsiones son los modelos 2 y 6, que minimizan el error en previsiones a 2 periodos, en el modelo 2 para Pernoctaciones y en el modelo 6 para Pernoctaciones por día.
* A medio y largo plazo el modelo 4 resulta tan competente como los modelos 2 y 6. De nuevo es un modelo que minimiza el error en previsiones a 2 periodos, pero ahora sobre el logaritmo de las Pernoctaciones.

Es decir, tanto la estrategia de predecir la serie de Pernoctaciones medias por día, (en lugar de la serie original) como la de usar como criterio para estimar los parámetros del modelo la minimización del error de previsión a dos periodos vista mejoran la calidad de las previsiones extra-muestrales. La combinación de estas dos estrategias es óptima para la previsiones a corto plazo y de las mejores para el medio y largo plazo.

\
\
\
\

