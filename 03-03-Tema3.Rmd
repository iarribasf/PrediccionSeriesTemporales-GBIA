---
title: "Métodos ingenuos de predicción. Evaluación de predicciones"
subtitle: "Previsión con Datos Temporales (GBIA)"
author: "Iván Arribas (Depto. Análisis Económico. Universitat de València)"
output: 
  html_document:
    code_download: yes
    df_print: kable
    fig_caption: no
    highlight: pygments
    number_sections: yes
    self_contained: yes
    theme: cerulean
    toc: yes
    toc_depth: 2
    toc_float:
      collapsed: yes
---

```{r chunk_setup, echo = FALSE}
knitr::opts_chunk$set(warning = FALSE, 
                      message = FALSE, 
                      comment = "",
                      fig.align = "center", 
                      fig.show = "hold",
                      fig.height = 4,
                      fig.width = 8,
                      out.width = "80%") 
```

```{r options_setup, echo = FALSE}
options(scipen = 999) #- para quitar la notacion cientifica
```

```{r librerias, echo = FALSE}
library("RColorBrewer")
library(forecast)
library(ggplot2); theme_set(theme_bw())
library(gridExtra)
library(grid)
```

# Introducción

En muchos casos es preciso aplicar un método de predicción rápido y sencillo:

* A causa del elevado número de series que tienen que ser analizadas.
* Debido a la rapidez con que las predicciones se han de dar.
      
Actualmente existen muchos métodos sencillos de predicción, entre lo que cabe destacar dos:

* __Métodos de media móvil__ (Tema 4).
* __Métodos de alisado exponencial__ (Tema 5).
    
Estas técnicas, a pesar de su sencillez, son bastante adecuadas cuando la previsión es a corto plazo:

>"Statistically sophisticated or complex methods do not necessarily produce more accurate forecasts than simpler ones." Makridakis y Hibon (2000).
      
Pero aún hay métodos más sencillos que quedan englobados bajo el paraguas de **métodos ingenuos** que veremos en este tema. 

\
\

# Criterios de calidad

En este tema y en los siguientes se verán diferentes métodos para predecir una serie temporal. Así, es preciso definir criterios de bondad de ajuste que permitan estimar tanto la calidad del ajuste como de las predicciones de un método.

> "The rankings of the performance of the various methods vary according to the accuracy measure being used."  Makridakis y Hibon (2000).
     
\

## Notación y definiciones


 
Dada una serie temporal $\{y_t\}_{t=1}^T$, se define:

* __Previsión $h$ periodos adelante__, como la previsión de la serie para el periodo $t+h$ disponiendo de información hasta el periodo $t$, y se denota por $\hat{y}_{t+h|t}$. Por simplicidad lo escribiremos también como $\hat{y}_{t+h}$.

\vspace{0.3cm}

* Así, $\hat{y}_{t+1|t}$ es la __previsión un periodo adelante__ o a un periodo vista. Es decir, la previsión de la serie en $t+1$ desde el periodo $t$.

\vspace{0.3cm}

* De nuevo, por simplicidad denotaremos a $\hat{y}_{t+1|t}$ como $\hat{y}_{t+1}$; y como $\hat{y}_{t}$ a la previsión en $t$, con datos hasta el periodo $t-1$ ($\hat{y}_{t} = \hat{y}_{t|t-1}$).

Se define como __error de previsión__, en este caso intra-muestral a un periodo vista, a 
$$\hat{e}_t=y_t-\hat{y}_t,$$
de forma que la serie $\{\hat{e}_t\}_{t=1}^T$ nos permitirá definir varios criterios de calidad de ajuste. 
  
\

## Medidas de precisión de la predicción
 
Dada una serie $\{y_t\}_{t=1}^T$, un método de predicción y su vector de errores asociado $\{\hat{e}_t\}_{t=1}^T$, podemos definir múltiples medidas de calidad del método de predicción. Las más habituales son (siglas en inglés):

* Error medio (ME): $\frac{1}{T}\sum_{t=1}^T \hat{e}_t$

\vspace{0.3cm}

* __Raíz del error cuadrático medio (RMSE)__: $\sqrt{\frac{1}{T}\sum_{t=1}^T \hat{e}^2_t}$

\vspace{0.3cm}

* Error absoluto medio (MAE): $\frac{1}{T}\sum_{t=1}^T |\hat{e}_t|$

\vspace{0.3cm}

* Error porcentual medio (MPE): $\frac{100}{T}\sum_{t=1}^T \frac{\hat{e}_t}{y_t}$

\vspace{0.3cm}

* __Error porcentual absoluto medio (MAPE)__: $\frac{100}{T}\sum_{t=1}^T \big|\frac{\hat{e}_t}{y_t}\big|$

\vspace{0.3cm}

* Error porcentual absoluto medio simétrico (sMAPE): $\frac{200}{T}\sum_{t=1}^T \Big|\frac{\hat{e}_t}{y_t + \hat{y}_t}\Big|$

\vspace{0.3cm}

* Error escalado absoluto medio (MASE): $\big(\frac{1}{T}\sum_{t=1}^T |\hat{e}_t|\big)/q$, donde $q$ es el error absoluto medio para un método ingenuo de predicción:
  * $q=\frac{1}{T-1}\sum_{t=2}^T |y_t-y_{t-1}|$ para series _sin_ estacionalidad
  * $q=\frac{1}{T-m}\sum_{t=m+1}^T |y_t-y_{t-m}|$ para series _con_ estacionalidad

\vspace{0.3cm}

* Correlación entre $\hat{e}_t$ y $\hat{e}_{t-1}$ (ACF1).

\

ME y MAE no permiten valorar la calidad de un modelo, pero si el posible sesgo de las predicciones.

* Lo esperado es un valor cercano a cero (con relación al valor medio de la serie). Valores muy alejados de cero son indicadores de sesgo de predicción.

RMSE y MAE indican el error medio cometido, medido en las mismas unidades que la serie temporal.

* Están acotadas inferiormente por el valor óptimo de 0, pero no hay cota superior.

MAPE y sMAPE indican el error porcentual medio cometido.

* Están acotadas inferiormente por el valor óptimo de 0%, y la cota superior natural es 100%, aunque podría sobrepasarse.
* Si $y_t$ puede valer 0, entonces MAPE no se puede calcular. Además, MAPE penaliza más los errores negativos frente a los errores positivos. La medida de precisión sMAPE se define a fin de corregir estos problemas.
      
MASE es la ratio entre el error del método usado y el error de un método ingenuo de predicción. Permite saber cuánto ganamos en capacidad predictiva al pasar de un método ingenuo a otro más complicado.

* Un valor cercano a 1 indica que el método usado no es mejor que el método ingenuo
* Cuanto más cercano a 0, mejor es el método usado respecto del método ingenuo
* Su complementario a 1 se puede interpretar como la tasa de mejora

ACF1 no es propiamente un indicador de calidad del modelo, pero indica la capacidad de mejora que hay en la estimación del intervalo de confianza de las predicciones. Lo veremos con más detalle en el siguiente tema. Por ahora basta saber que:

* Un valor cercano a 0 indica que hay poca capacidad de mejora.
* Un valor cercano a 1 o -1 indica que hay mucha capacidad de mejora.

Las _medias_ se pueden sustituir por _medianas_. Esto es especialmente útil cuando para algunas observaciones hay errores atípicamente altos.

\

Si estos indicadores de calidad se basan en predicciones intra-muestrales a un periodo vista, presentan dos problemas. Primero, evalúan el error de predicción a un periodo vista, cuando en muchas situaciones reales las predicciones se realizan sobre un horizonte temporal más amplio. Segundo, son errores intra-muestrales, resultantes de predecir los mismos datos que se han usado para estimar los parámetros del método de predicción y, por tanto, sobre-estiman la capacidad predictiva del modelo.

Veremos durante en este tema métodos de evaluación de la calidad de las predicciones que superan estas limitaciones.

\
\

# Métodos sencillos de predicción

Algunos métodos de predicción son extremadamente sencillos y sorprendentemente eficaces. A veces son los denominados métodos ingenuos. Estos métodos:

* posibilitan realizar predicciones prácticamente sin realizar ningún cálculo. 
* como son muy sencillos, dan las previsiones con mayor error (menos precisas). El error de un método ingenuo sirve de punto de referencia (_benchmark_) para valorar la necesidad de aplicar otros métodos más complicados con el objetivo de mejorar la calidad de las predicciones. 

Veamos algunos métodos sencillos y sus funciones en el paquete `forecast`.

\

## Métodos sencillos de predicción

### Series _sin_ tendencia y _sin_ estacionalidad {-}

**Método de la Media**: $\hat{y}_{T+h}=(y_1+\ldots,y_T)/T$.

* La predicción para cualquier periodo futuro es la __media__ de las observaciones disponibles previas.
* Función de `R`: `meanf(y, h)`
    
**Método ingenuo I**: $\hat{y}_{T+h}=y_T$.

* La predicción para cualquier periodo futuro es la __última__ observación disponible.
* Función de `R`: `naive(y, h)` o `rwf(y, h)` (_rw_ de random walk)


### Series _con_ tendencia y _sin_ estacionalidad {-}

**Método ingenuo II**: $\hat{y}_{T+h}=y_T + h(y_T-y_{T-1})$.

* La predicción $h$ periodos adelante es la __última observación__ disponible más $h$ veces el __último incremento__ observado. 
* No tiene función en `R`, pero se podría emular mediante la función `holt` (véase epígrafe de 4.5 Alisado exponencial de Holt).
      
**Método de la deriva**: $\hat{y}_{T+h}=y_T+h\frac{y_T - y_1}{T-1}$.

* La predicción $h$ periodos adelante es la __última observación__ disponible más $h$ veces el __incremento medio__ observado.
* Función de `R`: `rwf(y, h, drift = TRUE)`  


### Series _sin_ tendencia y _con_ estacionalidad {-}

**Método ingenuo con estacionalidad**: $\hat{y}_{T+h}=y_{T-m(k+1)}$.

* $k$ es la parte entera de $(h-1)/m$, es decir, el número de años completos en el periodo de predicción previo al periodo $T+h$.
* La predicción para un periodo es la __última observación disponible de la misma estación que la fecha que se desea predecir__.
* Función de `R`: `snaive(y, h)`
    
__No hay métodos sencillos cuando la serie tiene tendencia y estacionalidad__, aunque la aplicación del método ingenuo con estacionalidad suele ser muy efectiva.

\

## Ejemplo de aplicación

### Serie Libros {-}
 
```{r}
libros <- read.csv2("./series/libros.csv", header = TRUE)
libros <- ts(libros[ ,2], start = 1993, frequency  = 1)
```

En la figura 1 se muestra el resultado gráfico de la aplicación de algunos de estos métodos sencillos a la serie Libros (número de títulos publicados anualmente en España desde 1993 hasta 2018), con independencia de su adecuación dadas las componentes de esta serie. Se ha fijado un horizonte de previsión de cinco años (`h = 5`). El argumento `PI = FALSE` hace que no se impriman los intervalos de confianza de las predicciones.

Los métodos de la Media e Ingenuo I realizan una predicción constante, el primero la media de títulos en el periodo de análisis (`r as.integer(mean(libros))`) y el segundo el último dato observado (`r tail(as.integer(libros), n=1)`). El método de deriva ofrece una predicción creciente porque la serie Libros tiene una pendiente media positiva en el periodo de análisis.

Recuerda que debes cargar las librerías `forecast` y `ggplot2`.

```{r}
mediaLibros <- meanf(libros, h = 5)
naiveLibros <- naive(libros, h = 5)
derivaLibros <- rwf(libros,  h = 5, drift = TRUE)
 
autoplot(libros, series = "Libros",
                xlab = "",
                ylab = "Títulos",
                main = "Figura 1. Libros y predicción por métodos sencillos") +
  autolayer(mediaLibros, series="Media", PI = FALSE) +
  autolayer(naiveLibros, series="Ingenuo", PI = FALSE) +
  autolayer(derivaLibros, series="Deriva", PI = FALSE) +
  scale_colour_discrete(limits=c("Libros", "Media", "Ingenuo", "Deriva")) +
  guides(colour = guide_legend(title = "Métodos")) + 
  theme(legend.position=c(0.02,0.98), legend.justification=c(0,1))
```

Con la función `accuracy` se puede obtener el error de predicción intra-muestral a un periodo vista de cada método:

```{r, eval = FALSE}
accuracy(mediaLibros)
accuracy(naiveLibros)
accuracy(derivaLibros)
```

```{r, echo=FALSE}
tmp <- rbind(
  accuracy(mediaLibros),
  accuracy(naiveLibros),
  accuracy(derivaLibros)
)
tmp <- round(tmp,2)
rownames(tmp) <- c("Media","Ingenuo I","Deriva")
tmp
```

Podemos destacar que:

* El método de _Media_ presenta una baja capacidad predictiva debido a que la serie Libros tiene tendencia (MAPE =  14%). 
* El método de _Deriva_ tiene la mejor calidad de ajuste, con un error porcentual del 6.9% (MAPE), y un error medio aproximado de 6,000 títulos (RMSE).
* Para series sin estacionalidad el método sencillo de comparación usado en el cálculo del MASE es el _Ingenuo I_. Es por ello que este indicador vale 1 para este método.
* ACF1 indica que hay poco recorrido para mejorar la predicción por intervalo en los métodos Ingenuo I y Deriva.
* El error medio (ME) siempre será nulo para el método de la _Media_ y de la _Deriva_, lo que indica que nos equivocamos tanto por exceso como por defecto. Esta es una buena propiedad, que el método _Ingenuo I_ no verifica.

### Serie Nacimientos {-}

Podemos usar el método ingenuo con estacionalidad con la serie Nacimientos para obtener una previsión a dos años vista. El error absoluto porcentual medio es del 3.6%. Es decir, aplicando algo tan simple como predecir el número de nacimientos para un mes como los nacimientos del mismo mes del año previo, tenemos ya un error de predicción muy bajo. La figura 2 muestra la serie y la predicción que, debido al método usado, no incorpora la tendencia decreciente de los últimos años.

```{r}
nacimientos <- read.csv2("./series/nacimientos.csv", header = TRUE)
nacimientos <- ts(nacimientos[, 2],
                  start = c(1975, 1),
                  frequency = 12)

snaive.nacimientos <- snaive(nacimientos, h = 24, level = 95)
accuracy(snaive.nacimientos)

autoplot(snaive.nacimientos,
         xlab = "",
         ylab = "Nacimientos",
         main = "Figura 2. Nacimientos y predicción por el método Ingenuo con estacionalidad")
```

\
\

# Evaluación de las predicciones

Las medidas que hemos usado hasta ahora para valorar la calidad de las predicciones son realmente medidas de bondad de ajuste, es decir, medidas de la calidad de __previsiones intra-muestrales a un periodo vista__. Valoran en que medida los datos se ajustan a un patrón o modelo, pero no evalúan la calidad de la previsiones ante nuevos datos.

En este epígrafe vamos a ver dos metodologías que podemos usar para valorar la calidad de las __previsiones extra-muestrales__, que es realmente los que nos interesa. Estas dos metodologías están relacionadas con los métodos de _Training set/Test set_ y _Cross-validation_ que viste en _Previsión con datos transversales_, pero adaptadas a datos temporales.

## Validación por la metodología de _Training set/Test set_ para Series Temporales

Vamos a mejorar la estimación de la calidad de las predicciones obteniendo las medidas de error para __previsiones extra-muestrales a varios periodos vista__ usando la filosofía del método _training set/test set_. Dividimos la serie temporal $\{y_t\}_{t=1}^T$ en dos subseries, los primeros datos $\{y_t\}_{t=1}^{T_0}$, $T_0 < T$ se usarán para estimar el modelo, y los últimos datos $\{y_t\}_{t={T_0+1}}^{T}$ para validar el modelo.

Esta metodología, muy efectiva para datos de corte transversal, genera dos problemas cuando se aplica a series temporales: _i_) el error obtenido es una mezcla de errores de predicción a corto, medio y largo plazo difícil de valorar; _ii_) los resultados dependen tremendamente del punto de corte temporal seleccionado.

### Serie Libros {-}

Vamos a reservar, por ejemplo, las últimas 6 observaciones de la serie Libros y ajustar el modelo con las restantes. Después usaremos este modelo para calcular las predicciones a 6 periodos vista y compararlas con los valores reales de la serie. 

```{r, eval = FALSE}
# Definimos las observaciones intra- y extra-muestrales
librosIntra <- subset(libros, end = length(libros) - 6)
librosExtra <- subset(libros, start = length(libros) - 5)

# Estimamos el modelo con todos los datos menos los 6 ultimos y
# predecimos los 6 años que hemos quitado de la serie 
librosExtraPre <- rwf(librosIntra,  h = 6, drift = TRUE)

# Vemos la calidad del ajuste. Primero la predicción y luego los datos reales
accuracy(librosExtraPre, librosExtra)
```

```{r, echo = FALSE}
# Definimos las observaciones intra- y extra-muestrales
librosIntra <- subset(libros, end = length(libros) - 6)
librosExtra <- subset(libros, start = length(libros) - 5)

# Estimamos el modelo con todos los datos menos los 6 ultimos y
# predecimos los 7 años que hemos quitado de la serie 
librosExtraPre <- rwf(librosIntra,  h = 6, drift = TRUE)

# Vemos la calidad del ajuste. Primero la predicción y luego los datos reales
round(accuracy(librosExtraPre, librosExtra), 2)

error.muestral.1 <- round(accuracy(librosExtraPre, librosExtra)[1,5], 1)
error.extramuestral.n <- round(accuracy(librosExtraPre, librosExtra)[2,5],1)
```

Atendiendo al MAPE se tiene que el error de __previsión a un periodo vista__ en el __periodo intra-muestral__ de __1993 a 2012__ es del `r error.muestral.1`%; mientras que el error de __previsión a largo plazo__ en el __periodo extra-muestral__ de __2013 a 2018__ es del `r error.extramuestral.n`%. Ademas, para el periodo extra-muestral el error medio (ME) es negativo y muy elevado, un indicativo de que las previsiones están segadas (sobre-estiman la realidad). En resumen, la calidad del modelo se deteriora muy rápidamente en cuanto nos salimos de las condiciones óptimas. 

Un gráfico puede ayudar a entender este proceso de validación. En la figura 3:

* La línea de puntos vertical separa el periodo muestral (1993-2012) usado para estimar el modelo, del periodo extra-muestral (2013-2018) usado sólo para hacer las previsiones.
* La serie Libros aparece como una línea sólida en negro, desde 1993 hasta 2018.
* La previsión _intra_-muestral (a un periodo vista) de la serie Libros aparece como una línea azul.
* La línea en rojo es la previsión _extra_-muestral a largo plazo. Observa que todas las previsiones están por encima del valor real de la serie.
* Al lado de cada previsión (intra- y extra-muestral) se ha indicado el error estimado (MAPE).

Claramente estos resultados dependen del punto de corte seleccionado.

```{r,echo=FALSE}
autoplot(libros, series = "Libros",
         main="Figura 3. Libros, predicción intra- y extra-muestral",
         xlab="", 
         ylab="Títulos"
         ) +
  autolayer(fitted(librosExtraPre), series = "Libros (ajustada)") + 
  autolayer(librosExtraPre$mean, series = "Predicción") + 
  geom_vline(xintercept = 2012.5, lty = 2, col = "black") +
  scale_colour_manual(values=c("Libros"="black",
                               "Libros (ajustada)"="blue", 
                               "Predicción" = "red")) +
  guides(colour = guide_legend(title = "Series")) +
  annotate("text", x=1999, y=65000, label="6.5%", colour = "blue") +
  annotate("text", x=2016, y=72000, label="26.7%", colour = "red") +
  theme(legend.position=c(0.02,0.98), legend.justification=c(0,1)) 
```

### Serie Nacimientos {-}

Calculamos de nuevo los diferentes criterios de bondad de ajuste para valorar la calidad de las previsiones extra-muestrales a largo plazo. En este caso vamos a reservar los últimos 36 meses como periodo extra-muestral.
  
```{r, eval = FALSE}
nacimientosIntra <- subset(nacimientos, end = length(nacimientos) - 36)
nacimientosExtra <- subset(nacimientos, start = length(nacimientos) - 35)

nacimientosExtraPre <- snaive(nacimientosIntra, h = 36)

accuracy(nacimientosExtraPre, nacimientosExtra)
```

```{r, echo = FALSE}
nacimientosIntra <- subset(nacimientos, end = length(nacimientos) - 36)
nacimientosExtra <- subset(nacimientos, start = length(nacimientos) - 35)

nacimientosExtraPre <- snaive(nacimientosIntra, h = 36)

round(accuracy(nacimientosExtraPre, nacimientosExtra), 2)
```

```{r, echo = FALSE}
autoplot(nacimientos, series = "Nacimientos",
         main="Figura 4. Nacimientos, predicción intra- y extra-muestral",
         xlab="", 
         ylab="Nacimientos"
         ) +
  autolayer(fitted(nacimientosExtraPre), series = "Nacimientos (ajustada)") + 
  autolayer(nacimientosExtraPre$mean, series = "Predicción") + 
  scale_colour_manual(values=c("Nacimientos"="black",
                               "Nacimientos (ajustada)"="blue", 
                               "Predicción" = "red")) +
  guides(colour = guide_legend(title = "Series")) +
  annotate("text", x=2012, y=45000, label="3.6%", colour = "blue") +
  annotate("text", x=2018, y=40000, label="7.7%", colour = "red") + 
  theme(legend.position=c(0.98,0.98), legend.justification=c(1,1)) 
```

Las previsiones extra-muestrales muestran una menor pendiente que los casos reales de nacimientos. Así, conforme se avanza en el horizonte temporal las previsiones se van alejando de la realidad y el error extra-muestral es del 7.7%, reducido pero que duplica el error de estimación intra-muestral (3.6%).

\

## Validación cruzada para Series Temporales

Hemos visto dos alternativas para evaluar la calidad de un método de predicción de series temporales, uno basado en predicciones intra-muestrales a un periodo vista y otro basado en predicciones extra-muestrales a largo plazo, ambas con sus inconvenientes.

Veamos ahora una técnica, basada en el concepto de validación cruzada (_cross validation_) que permite obtener de forma individualizada los errores de previsión extra-muestral a un periodo vista, a dos periodos vista, etc.

Supongamos que para estimar el modelo se necesita un mínimo de $k$ observaciones y que se desea predecir hasta un horizonte temporal $h$.

* Seleccionamos las observaciones $1,2,...,k$ para estimar el modelo y predecimos las observaciones desde $k+1$ hasta $k+h$. Tenemos, por tanto, $h$ predicciones.
* Calculamos el error de predicción para las predicciones desde $k+1$ hasta $k+h$.
* Repetimos este proceso desplazando el número de observaciones seleccionadas para la estimación un periodo adelante. Es decir, ahora usamos las observaciones $2,3,...,k+1$ para estimar el modelo, predecimos las observaciones desde $k+2$ hasta $k+1+h$ y calculamos el error de predicción.
* Iteramos el proceso, desplazando cada vez las observaciones de la estimación un periodo adelante.
* En general para $i=0,1,...,T-k-h$, donde $T$ es el número total de observaciones:
  
  1. Seleccionamos las observaciones $i+1,i+2,...,i+k$ para estimar el modelo.
  2. Predecimos las observaciones desde $i+k+1$ hasta $i+k+h$.
  3. Calculamos el error de predicción para las observaciones desde $i+k+1$ hasta $i+k+h$.
  4. Para cada horizonte temporal de predicción se calcula la medida de error deseada.

\
\

![](./imagenes/RollingWindows.png)

Este procedimiento se denomina __origen de predicción móvil__ (_rolling forecast origin_) o _rolling windows_.

Cuando se aplica esta metodología hay que tener en cuenta que los resultados pueden depender del número $k$ de datos usados para la estimación del modelo.

### Ejemplo de aplicación con Nacimientos {-}

Vamos a aplicar la metodología previa a la serie de Nacimientos. Asumimos que se precisan diez años para hacer una buena estimación, $k=120$, y que el horizonte temporal es de tres años, $h = 36$ meses. La siguiente rutina permite obtener el MAPE para previsiones con un horizonte temporal desde 1 mes hasta 36 meses.
  
```{r}  
k <- 120                  #Minimo numero de datos para estimar
h <- 36                   #Horizonte de las prediciciones
TT <- length(nacimientos) #Longitud serie
s <- TT - k - h           #Total de estimaciones

mapeSnaive <- matrix(NA, s + 1, h)
for (i in 0:s) {
  train.set <- subset(nacimientos, start = i + 1, end = i + k)
  test.set <-  subset(nacimientos, start = i + k + 1, end = i + k + h)
  
  fcast <- snaive(train.set, h = h)
  mapeSnaive[i + 1,] <- 100*abs(test.set - fcast$mean)/test.set
}

mapeSnaive <- colMeans(mapeSnaive)

ggplot() +
  geom_line(aes(x = 1:h, y = mapeSnaive)) +
  ggtitle("Figura 5. Error de predicción según horizonte temporal") +
  xlab("Horizonte temporal de predicción") +
  ylab("MAPE") +
  scale_x_continuous(breaks= 1:h)
```

La figura 5 muestra el error de previsión extra-muestral según el horizonte de previsión. Se observa como para el primer año el error de predicción se mantiene por debajo del 3.5% y prácticamente constante. Sin embargo, para el segundo año de predicción el MAPE salta al 5.5%, y para el tercer año pasa al 7.5%. Usar las ultimas observaciones parece un buen método para predecir a un año vista, pero no a dos o tres años vista, máxime cuando la serie presenta tendencia.

\
\

# Resumen de los comandos utilizados


|Función  |Paquete | Descripción                                           |
|:--------------|:-----------|:-----------------------------------------------------|
|`meanf`        |forecast  |Predicción por media |
|`naive`        |forecast  |Predicción por método ingenuo I |
|`rwf`          |forecast  |Predicción con tendencia media |
|`snaive`	      |forecast  |Predicción por método ingenuo con estacionalidad |
|`accuracy`	    |forecast  |Calculo de la precisión del modelo |
|`forecast`     |forecast  |Predice valores extra-muestrales futuros de la serie |
|`fitted`       |stats     |Obtiene las predicciones a un periodo vista intra-muestrales|

\
\

# Referencias

* Makridakis, S. y  Hibon, M. (2000). _The M3-Competition: results, conclusions and implications_. International Journal of Forecasting, 16(4), pp. 451–476. doi:10.1016/S0169-2070(00)00057-1


\
\
\
\
