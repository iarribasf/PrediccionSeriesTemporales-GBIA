<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Iván Arribas (Depto. Análisis Económico. Universitat de València)" />


<title>Técnicas de Alisado Exponencial</title>

<script src="site_libs/header-attrs-2.11/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cerulean.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script src="site_libs/navigation-1.1/codefolding.js"></script>
<script src="site_libs/navigation-1.1/sourceembed.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>


<style type="text/css">
  code {
    white-space: pre;
  }
  .sourceCode {
    overflow: visible;
  }
</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    for (var j = 0; j < rules.length; j++) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") continue;
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') continue;
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>


<style type="text/css">
#rmd-source-code {
  display: none;
}
</style>


<link rel="stylesheet" href="styles.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-inverse  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Predicción con Datos Temporales</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">
    <span class="fa fa-home"></span>
     
  </a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="01-Guia-curso.html">
    <span class="fa fa-graduation-cap"></span>
     
    Guía del curso
  </a>
</li>
<li>
  <a href="02-Logistica.html">
    <span class="fa fa-laptop"></span>
     
    Logística
  </a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-book"></span>
     
    Diapos
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Teoría</li>
    <li>
      <a href="03-01-Tema1.html">Tema 1: Introducción</a>
    </li>
    <li>
      <a href="03-02-Tema2.html">Tema 2: Definición</a>
    </li>
    <li>
      <a href="03-03-Tema3.html">Tema 3: Métodos sencillos</a>
    </li>
    <li>
      <a href="03-04-Tema4.html">Tema 4: Media móvil</a>
    </li>
    <li>
      <a href="03-05-Tema5.html">Tema 5: Alisado</a>
    </li>
    <li>
      <a href="03-06-Tema6.html">Tema 6: ARIMA</a>
    </li>
    <li>
      <a href="03-07-Tema7.html">Tema 7: SARIMA</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Ejemplo de aplicación</li>
    <li>
      <a href="03-08-Ejemplo2.html">Ejemplo Tema 2</a>
    </li>
    <li>
      <a href="03-09-Ejemplo3.html">Ejemplo Tema 3</a>
    </li>
    <li>
      <a href="03-10-Ejemplo4.html">Ejemplo Tema 4</a>
    </li>
    <li>
      <a href="03-11-Ejemplo5.html">Ejemplo Tema 5</a>
    </li>
    <li>
      <a href="03-12-Ejemplo6.html">Ejemplo Tema 6</a>
    </li>
    <li>
      <a href="03-13-Ejemplo7.html">Ejemplo Tema 7</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Otro ejemplo</li>
    <li>
      <a href="03-14-Ejemplo-Pasajeros.html">Ejemplo de Pasajeros</a>
    </li>
  </ul>
</li>
<li>
  <a href="04-Recursos-R.html">
    <span class="fa fa-code"></span>
     
    Recursos de R
  </a>
</li>
<li>
  <a href="05-Evaluacion_Continua.html">
    <span class="fa fa-edit"></span>
     
    Evaluacion Continua
  </a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-download"></span>
     
    Más
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">R</li>
    <li>
      <a href="https://cran.r-project.org">Dónde está R</a>
    </li>
    <li>
      <a href="https://rstudio.com">Donde está RStudio</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Markdown</li>
    <li>
      <a href="https://bookdown.org/yihui/rmarkdown/">Markdown</a>
    </li>
    <li>
      <a href="https://rmarkdown.rstudio.com/lesson-1.html">R Markdown</a>
    </li>
    <li>
      <a href="https://www.rstudio.com/wp-content/uploads/2015/03/rmarkdown-reference.pdf">R Markdown (pdf)</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Otros</li>
    <li>
      <a href="https://www.r-bloggers.com">Blog sobre R</a>
    </li>
    <li>
      <a href="https://bookdown.org">Libros online que debes conocer</a>
    </li>
  </ul>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">

<div class="btn-group pull-right float-right">
<button type="button" class="btn btn-default btn-xs btn-secondary btn-sm dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu dropdown-menu-right" style="min-width: 50px;">
<li><a id="rmd-download-source" href="#">Download Rmd</a></li>
</ul>
</div>



<h1 class="title toc-ignore">Técnicas de Alisado Exponencial</h1>
<h3 class="subtitle">Previsión con Datos Temporales (GBIA)</h3>
<h4 class="author">Iván Arribas (Depto. Análisis Económico. Universitat de València)</h4>

</div>


<p><br />
<br />
</p>
<div id="introducción" class="section level1" number="1">
<h1 number="1"><span class="header-section-number">1</span> Introducción</h1>
<p>Los métodos de alisado exponencial aparecen en los años 50 de la mano de Brown, Holt y Winters y han sido la raíz de uno de los métodos de predicción más sencillos y eficaces. La idea básica es predecir usando una media ponderada de los datos pasados, donde los más recientes tienen un peso mayor y este decae exponencialmente conforme usamos observaciones más antiguas.</p>
<p>El alisado exponencial es una familia de métodos de ajuste y previsión que ofrece muy buenos resultados para predicciones a corto plazo o para predecir series con pocos datos o <em>sencillas</em> (sin mucho <em>ruido</em>).</p>
<p>Suponen un grado de modelización mayor que los métodos sencillos vistos previamente, pero sin alcanzar la complejidad de otras metodologías (modelos ARIMA).</p>
<p>En origen, son métodos descriptivos con el único objetivo de producir <strong>predicciones puntuales</strong>. Sin embargo, su enfoque como modelos de <em>espacio de estados</em> posibilita un marco teórico para obtener <strong>intervalos de predicción</strong>.</p>
<p><br />
<br />
</p>
</div>
<div id="componentes-de-una-serie-en-el-contexto-del-alisado-exponencial" class="section level1" number="2">
<h1 number="2"><span class="header-section-number">2</span> Componentes de una serie en el contexto del alisado exponencial</h1>
<p>Para obtener una predicción en el periodo <span class="math inline">\(t+1\)</span> con datos hasta el periodo <span class="math inline">\(t\)</span> necesitamos tres componentes:</p>
<ul>
<li>La estimación del nivel de la serie en el periodo <span class="math inline">\(t\)</span>: <span class="math inline">\(l_t\)</span></li>
<li>La estimación de la pendiente de la serie en el periodo <span class="math inline">\(t\)</span>: <span class="math inline">\(b_t\)</span></li>
<li>La estimación de la estacionalidad en el mes correspondiente al periodo <span class="math inline">\(t+1\)</span> con datos hasta <span class="math inline">\(t\)</span>: <span class="math inline">\(s_{t + 1 - m}\)</span> (recuerda, <span class="math inline">\(m\)</span> es el orden estacional</li>
</ul>
<p>A partir de estas componentes, obtenidas en el periodo <span class="math inline">\(t\)</span> y para un esquema aditivo, se tendría que la predicción en el periodo <span class="math inline">\(t+1\)</span> es: <span class="math display">\[\widehat{y}_{t+1} = l_t+b_t+s_{t+1-m}.\]</span> En general, las componentes pueden <strong>existir o no</strong> y se pueden combinar entre ellas <strong>aditiva o multiplicativamente</strong>. Veamos algunos casos:</p>
<ul>
<li>Existen todas y son multiplicativas: <span class="math display">\[\widehat{y}_{t+1}=l_t \cdot b_t \cdot s_{t + 1 - m}\]</span></li>
<li>Existen todas, nivel y pendiente aditivas, y estacionalidad multiplicativa: <span class="math display">\[\widehat{y}_{t+1}=(l_t+b_t)s_{t + 1 - m}\]</span></li>
<li>No hay pendiente y la estacionalidad es aditiva: <span class="math display">\[\widehat{y}_{t+1}=l_t+s_{t + 1 - m}\]</span></li>
</ul>
<p>¿Como obtenemos los valores de <span class="math inline">\(l_t\)</span>, <span class="math inline">\(b_t\)</span> y <span class="math inline">\(s_{t + 1 - m}\)</span>? Mediante <strong>expresiones recursivas</strong>, donde cada componente se calcula a partir de los valores hasta <span class="math inline">\(t\)</span> de la serie y de las componentes: <span class="math display">\[
\begin{aligned}
l_t&amp; = f_l(y_t,y_{t-1}\ldots, l_{t-1},l_{t-2}\ldots,b_{t-1},b_{t-2}\ldots,s_{t-1},s_{t-2}\ldots) \\
b_t&amp; = f_b(y_t,y_{t-1}\ldots, l_{t},l_{t-1}\ldots,b_{t-1},b_{t-2}\ldots,s_{t-1},s_{t-2}\ldots) \\
s_t&amp; = f_s(y_t,y_{t-1}\ldots, l_{t},l_{t-1}\ldots,b_{t},b_{t-1}\ldots,s_{t-1},s_{t-2}\ldots)
\end{aligned}
\]</span> Por ejemplo, el <em>método ingenuo I</em> se puede interpretar dentro de este contexto como un método de alisado donde <span class="math inline">\(l_t = y_t\)</span> y no hay ni pendiente ni estacionalidad. Por tanto, <span class="math inline">\(\widehat{y}_{T+1} = l_{T} = y_{T}\)</span>.</p>
<p>De la misma forma, el <em>método ingenuo II</em> se puede interpretar como un método de alisado donde <span class="math inline">\(l_t = y_t\)</span>, <span class="math inline">\(b_t = y_t - y_{t-1}\)</span> y no hay estacionalidad. Entonces, <span class="math inline">\(\widehat{y}_{T+1}=l_T + b_T = y_T + (y_T - y_{T-1})\)</span>.</p>
<p>En las expresiones previas hemos supuesto que se quería obtener una predicción a un periodo vista (<span class="math inline">\(\widehat{y}_{t+1}\)</span>). Si el objetivo es estimar una previsión <span class="math inline">\(h\)</span> periodos hacia delante desde el periodo <span class="math inline">\(t\)</span>, <span class="math inline">\(\widehat{y}_{t+h}\)</span>, hay que modificar la ecuación de predicción adecuadamente. Por ejemplo, para el caso aditivo se tendría que <span class="math display">\[\widehat{y}_{t+h} = l_t+hb_t+s_{t+h-m(k+1)}\]</span> donde <span class="math inline">\(k = \lfloor (h-1)/m\rfloor\)</span>.</p>
<p>El concepto de componentes aquí visto no coincide con el definido en el Tema 1. Sin embargo, podemos asimilar la tendencia de una serie como la suma (multiplicación) del nivel y la pendiente <span class="math inline">\(T_{t+1} = l_t + b_t\)</span> (<span class="math inline">\(T_{t+1} = l_t \cdot b_t\)</span>) y de esta forma ambas definiciones de componentes de una serie se hacen compatibles.</p>
<p><br />
<br />
</p>
</div>
<div id="casos-posibles" class="section level1" number="3">
<h1 number="3"><span class="header-section-number">3</span> Casos posibles</h1>
<p>Todas las series tiene nivel, pero dependiendo del tipo de pendiente y estacionalidad hay 15 casos posibles, mostrados en la tabla siguiente.</p>
<table>
<thead>
<tr class="header">
<th align="left">Tendencia</th>
<th align="center"></th>
<th align="center">Estacionalidad</th>
<th align="center"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"></td>
<td align="center">Ninguna (N)</td>
<td align="center">Aditiva (A)</td>
<td align="center">Multiplicativa (M)</td>
</tr>
<tr class="even">
<td align="left">Ninguna (N)</td>
<td align="center"><strong>N, N</strong></td>
<td align="center">N, A</td>
<td align="center">N, M</td>
</tr>
<tr class="odd">
<td align="left">Aditiva (A)</td>
<td align="center"><strong>A, N</strong></td>
<td align="center"><strong>A, A</strong></td>
<td align="center"><strong>A, M</strong></td>
</tr>
<tr class="even">
<td align="left">Aditiva Amortiguada (Ad)</td>
<td align="center"><strong>Ad, N</strong></td>
<td align="center">Ad, A</td>
<td align="center">Ad, M</td>
</tr>
<tr class="odd">
<td align="left">Multiplicativa (M)</td>
<td align="center">M, N</td>
<td align="center">M, A</td>
<td align="center">M, M</td>
</tr>
<tr class="even">
<td align="left">Multiplicativa Amortiguada (Md)</td>
<td align="center">Md, N</td>
<td align="center">Md, A</td>
<td align="center">Md, M</td>
</tr>
</tbody>
</table>
<p>Cada caso difiere en las componentes que se observan y su esquema, dando lugar a un conjunto diferente de ecuaciones recursivas de actualización.</p>
<p>Si se añade que el error puede ser aditivo o multiplicativo, da 30 posibilidades. El tipo de error (aditivo o multiplicativo) no afecta ni a la estimación ni a la previsión puntual, sólo es relevante en el cálculo del intervalo de confianza de las predicciones.</p>
<p>Los modelos más usuales son:</p>
<ul>
<li>(N, N): Alisado exponencial simple</li>
<li>(A, N): Alisado de Holt</li>
<li>(Ad, N): Alisado con tendencia amortiguada (d de <em>damped</em>)</li>
<li>(A, A): Alisado de Holt-Winters aditivo</li>
<li>(A, M): Alisado de Holt-Winters multiplicativo</li>
</ul>
<p>Acude al artículo de <a href="http://www.jstatsoft.org/v27/i03/paper">Rob J. Hyndman y Yeasmin Khandakar (2008)</a> para saber más de cada modelo, o al libro <em>Forecasting with Exponential Smoothing: the State Space Approach</em> (2008) de Hyndman y otros autores.</p>
<p><br />
<br />
</p>
</div>
<div id="alisado-exponencial-simple-n-n" class="section level1" number="4">
<h1 number="4"><span class="header-section-number">4</span> Alisado exponencial simple (N, N)</h1>
<p><br />
</p>
<div id="definición" class="section level2" number="4.1">
<h2 number="4.1"><span class="header-section-number">4.1</span> Definición</h2>
<p>El alisado exponencial simple es adecuado para una serie estacionaria y sin estacionalidad. Es decir, una serie que se mueve alrededor de un nivel constante.</p>
<p>La ecuación de la <strong>predicción intra-muestral</strong> es <span class="math display">\[\widehat{y}_{t+1} = \alpha y_t + \alpha (1-\alpha) y_{t-1} + \alpha (1-\alpha)^2 y_{t-2} + \alpha (1-\alpha)^3 y_{t-3} + \ldots =  \alpha y_t + (1-\alpha)\widehat{y}_{t},\]</span> donde <span class="math inline">\(0 \leq \alpha \leq 1\)</span> es el parámetro de suavizado. La primera <strong>predicción extra-muestral</strong> queda <span class="math display">\[\widehat{y}_{T+1}=\alpha y_T + (1-\alpha)\widehat{y}_{T}\]</span> y para las restantes <span class="math display">\[\widehat{y}_{T+h} = \widehat{y}_{T+1}.\]</span><br />
</p>
</div>
<div id="formulas-interactivas-de-sus-componentes" class="section level2" number="4.2">
<h2 number="4.2"><span class="header-section-number">4.2</span> Formulas interactivas de sus componentes</h2>
<p>En el alisado exponencial simple solo hay una componente, el nivel <span class="math inline">\(l_t\)</span>.</p>
<ul>
<li>La <strong>ecuación recursiva</strong> de suavizado es <span class="math inline">\(l_t=\alpha y_t + (1-\alpha)l_{t-1}\)</span></li>
<li>La ecuación de <strong>predicción intra-muestral</strong> es <span class="math inline">\(\widehat{y}_{t+1} = l_t\)</span></li>
<li>La ecuación de <strong>predicción extra-muestral</strong> es <span class="math inline">\(\widehat{y}_{T+h} = \widehat{y}_{T+1} = l_T\)</span></li>
</ul>
<p>Dos estimaciones razonables de <span class="math inline">\(l_t\)</span>, el nivel de la serie en el periodo <span class="math inline">\(t\)</span>, son el valor observado para la serie en ese periodo <span class="math inline">\(y_t\)</span> y el nivel del periodo previo <span class="math inline">\(l_{t-1}\)</span>. La estimación final de <span class="math inline">\(l_t\)</span> es una media ponderada de ambas y esta estimación final es la previsión de la serie para el periodo siguiente.</p>
<p><br />
</p>
</div>
<div id="estimación-de-los-parámetros-del-modelo" class="section level2" number="4.3">
<h2 number="4.3"><span class="header-section-number">4.3</span> Estimación de los parámetros del modelo</h2>
<p>Dado el proceso iterativo para el cálculo de <span class="math inline">\(l_t\)</span> se necesita un <strong>valor inicial</strong> de arranque <span class="math inline">\(l_0\)</span>. Cada programa estadístico usa su propio método para obtener <span class="math inline">\(l_0\)</span>.</p>
<p>Respecto de <span class="math inline">\(\alpha\)</span>, usualmente se estima el valor <strong>optimo</strong> según un criterio de precisión de la predicción. El parámetro <span class="math inline">\(\alpha\)</span> <strong>se puede interpretar</strong> como:</p>
<ul>
<li>Si <span class="math inline">\(\alpha = 1\)</span> se tiene el <em>método ingenuo I</em> (<span class="math inline">\(\widehat{y}_{t+1}=y_t\)</span>), óptimo cuando el nivel de la serie varía constantemente en el tiempo.</li>
<li>Si <span class="math inline">\(\alpha = 0\)</span> se tiene <span class="math inline">\(\widehat{y}_{t} =l_0\)</span>, óptimo cuando el nivel permanece constante en el tiempo.</li>
</ul>
<p><br />
</p>
</div>
<div id="ejemplo" class="section level2" number="4.4">
<h2 number="4.4"><span class="header-section-number">4.4</span> Ejemplo</h2>
<p>Vamos a usar el método de alisado exponencial simple para predecir la serie Libros. Usaremos para ello la función <code>ses</code> (<em>simple exponential smoothing</em>) con una previsión a 5 años vista (<code>h = 5</code>). Esta función estima los valores de <span class="math inline">\(l_0\)</span> y <span class="math inline">\(\alpha\)</span> que maximizan la función de verosimilitud, pero se pueden elegir otros criterios con el parámetro <code>opt.crit</code>.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>libros <span class="ot">&lt;-</span> <span class="fu">read.csv2</span>(<span class="st">&quot;./series/libros.csv&quot;</span>, <span class="at">header =</span> <span class="cn">TRUE</span>)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>libros <span class="ot">&lt;-</span> <span class="fu">ts</span>(libros[, <span class="dv">2</span>], <span class="at">start =</span> <span class="dv">1993</span>, <span class="at">frequency  =</span> <span class="dv">1</span>)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>librosf <span class="ot">&lt;-</span> <span class="fu">ses</span>(libros, <span class="at">h =</span> <span class="dv">5</span>, <span class="at">level =</span> <span class="dv">95</span>)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(librosf)</span></code></pre></div>
<pre><code>
Forecast method: Simple exponential smoothing

Model Information:
Simple exponential smoothing 

Call:
 ses(y = libros, h = 5, level = 95) 

  Smoothing parameters:
    alpha = 0.9756 

  Initial states:
    l = 40846.9233 

  sigma:  6135.033

     AIC     AICc      BIC 
542.1615 543.2524 545.9358 

Error measures:
                   ME     RMSE      MAE      MPE     MAPE     MASE        ACF1
Training set 839.0525 5894.349 4452.239 1.240605 7.032466 0.962355 -0.01829562

Forecasts:
     Point Forecast    Lo 95    Hi 95
2019       62131.07 50106.63 74155.52
2020       62131.07 45331.71 78930.44
2021       62131.07 41640.83 82621.32
2022       62131.07 38520.03 85742.12
2023       62131.07 35766.08 88496.07</code></pre>
<p>Veamos la salida en detalle:</p>
<ul>
<li>El valor de <span class="math inline">\(\alpha\)</span> que optimiza el criterio usado para medir la calidad del ajuste es <span class="math inline">\(\alpha =\)</span> 0.98, un valor muy cercano a 1. Esto es un indicativo de que: i) la serie Libros cambia de nivel de forma constante, un rasgo en los procesos puramente estocásticos como el paseo aleatorio; y ii) el método de alisado exponencial simple se aproxima al método Ingenuo I.</li>
<li>El valor de arranque <span class="math inline">\(l_0\)</span> óptimo es 40846.92.</li>
<li><em>sigma</em> es la desviación típica del error (aditivo) de predicción. Se diferencia de RMSE en el denominador. Para calcular <em>sigma</em> en lugar de dividir por <span class="math inline">\(T\)</span> se divide por <span class="math inline">\(T\)</span> menos el número de parámetros estimados (en este caso 3, <span class="math inline">\(l_0\)</span>, <span class="math inline">\(\alpha\)</span> y <em>sigma</em>).</li>
<li>La calidad del ajuste es razonable, como evidencia el error porcentual medio del 7%.</li>
<li>Las predicciones son las mismas para los 5 años, como cabe esperar (recuerda que <span class="math inline">\(\widehat{y}_{T+h} = l_T\)</span>).</li>
</ul>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tail</span>(librosf<span class="sc">$</span>model<span class="sc">$</span>states, <span class="at">n =</span> <span class="dv">4</span>)</span></code></pre></div>
<pre><code>Time Series:
Start = 2015 
End = 2018 
Frequency = 1 
            l
[1,] 60887.22
[2,] 59599.15
[3,] 60170.73
[4,] 62131.07</code></pre>
<p>En el objeto <code>librosf</code> la matriz <code>librosf$model$states</code> guarda todos los valores del nivel obtenidos con la ecuación recursiva, incluidos el valor de arranque, así que es una matriz con <span class="math inline">\(T+1\)</span> filas. Puedes ver el valor de <span class="math inline">\(l_{2018}\)</span> en su última fila, que vale 62131.07. Así, la predicción para <span class="math inline">\(2019\)</span> es <span class="math inline">\(\widehat{y}_{2019}=l_{2018}=\)</span> 62131.07. Igualmente <span class="math inline">\(\widehat{y}_{2020}=l_{2018}=\)</span> 62131.07. Es decir, todas las previsiones son iguales a <span class="math inline">\(l_{2018}\)</span>.</p>
<p>La figura 1 muestra la serie Libros, las previsiones extra-muestrales que son constantes y el intervalo de confianza. Conforme aumentamos el horizonte de predicción, el intervalo de confianza es más amplio como reflejo de la mayor incertidumbre en la predicción.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(librosf,</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>         <span class="at">xlab =</span> <span class="st">&quot;&quot;</span>,</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>         <span class="at">ylab =</span> <span class="st">&quot;Títulos&quot;</span>,</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>         <span class="at">main =</span> <span class="st">&quot;Figura 1. Libros y predicción con alisado simple&quot;</span>)</span></code></pre></div>
<p><img src="03-05-Tema5_files/figure-html/unnamed-chunk-3-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p><br />
<br />
</p>
</div>
</div>
<div id="alisado-exponencial-de-holt-a-n" class="section level1" number="5">
<h1 number="5"><span class="header-section-number">5</span> Alisado exponencial de Holt (A, N)</h1>
<p>El alisado exponencial de Holt es adecuado para una serie no estacionaria y sin estacionalidad.</p>
<p><br />
</p>
<div id="formulas-interactivas-de-sus-componentes-1" class="section level2" number="5.1">
<h2 number="5.1"><span class="header-section-number">5.1</span> Formulas interactivas de sus componentes</h2>
<p>Las <strong>ecuaciones recursivas</strong> son <span class="math display">\[
\begin{aligned}
l_t &amp; =\alpha y_t + (1-\alpha)(l_{t-1}+b_{t-1}) \\
b_t &amp; =\beta (l_t - l_{t-1}) + (1-\beta)b_{t-1} 
\end{aligned}
\]</span> La ecuación de la <strong>predicción intra-muestral</strong> a un periodo vista es <span class="math display">\[\widehat{y}_{t+1} = l_t + b_t,\]</span> de forma que la ecuación de <strong>predicción extra-muestral</strong> es <span class="math display">\[\widehat{y}_{T+h}=l_T + h b_T.\]</span></p>
<p>Dos estimaciones razonables del nivel de la serie en el periodo <span class="math inline">\(t\)</span> son el valor observado para la serie en ese periodo <span class="math inline">\(y_t\)</span>, y una estimación del nivel del periodo <span class="math inline">\(t\)</span> realizada desde el periodo <span class="math inline">\(t-1\)</span>: <span class="math inline">\(l_{t-1} + b_{t-1}\)</span>. Por otro lado, dos estimaciones razonables de la pendiente de la serie en el periodo <span class="math inline">\(t\)</span> son el cambio de nivel de <span class="math inline">\(t-1\)</span> a <span class="math inline">\(t\)</span> (el último observado) <span class="math inline">\(l_t-l_{t-1}\)</span>, y el valor de la pendiente en el periodo previo, <span class="math inline">\(b_{t-1}\)</span>. En ambos casos, nivel y pendiente, la estimación final es una media ponderada, parametrizada por <span class="math inline">\(0 \leq \alpha, \: \beta \leq 1\)</span>.</p>
<p><br />
</p>
</div>
<div id="estimación-de-los-parámetros-del-modelo-1" class="section level2" number="5.2">
<h2 number="5.2"><span class="header-section-number">5.2</span> Estimación de los parámetros del modelo</h2>
<p>Para aplicar este método es necesario estimar unos valores iniciales <span class="math inline">\(l_0\)</span> y <span class="math inline">\(b_0\)</span> de las ecuaciones recursivas e identificar los valores más adecuados de los parámetros <span class="math inline">\(\alpha\)</span> y <span class="math inline">\(\beta\)</span>. Los <strong>valores óptimos</strong> de estos cuatro parámetros se obtienen optimizando una medida de precisión de las predicciones.</p>
<p>La interpretación del parámetro <span class="math inline">\(\alpha\)</span> es similar al caso del alisado exponencial simple.</p>
<p><strong>Interpretación del parámetro <span class="math inline">\(\beta\)</span></strong>:</p>
<ul>
<li>Si <span class="math inline">\(\beta = 1\)</span>, <span class="math inline">\(b_t = l_t - l_{t-1}\)</span>, la pendiente se actualiza constantemente porque varía periodo a periodo Puede ser un indicador de mal ajuste (tendencia no lineal o pendiente no aditiva).</li>
<li>Si <span class="math inline">\(\beta = 0\)</span>, <span class="math inline">\(b_t = b_{t-1}= \ldots = b_0\)</span>, la pendiente se mantiene constante en el tiempo.</li>
</ul>
<p>El <em>método ingenuo II</em> es un caso concreto de Alisado de Holt. Si hacemos <span class="math inline">\(\alpha=\beta = 1\)</span>, queda <span class="math inline">\(l_t=y_t\)</span> y <span class="math inline">\(b_t=y_t-y_{t-1}\)</span>, por tanto <span class="math display">\[\widehat{y}_{T+h}=l_T + h \cdot b_T = y_T + h(y_T - y_{T-1}).\]</span></p>
<p><br />
</p>
</div>
<div id="ejemplo-1" class="section level2" number="5.3">
<h2 number="5.3"><span class="header-section-number">5.3</span> Ejemplo</h2>
<p>Vamos a usar el método de alisado de Holt para predecir de nuevo la serie Libros. Usaremos para ello la función <code>holt</code> con una previsión a 5 años vista (<code>h = 5</code>).</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>librosf <span class="ot">&lt;-</span> <span class="fu">holt</span>(libros, <span class="at">h =</span> <span class="dv">5</span>, <span class="at">level =</span> <span class="dv">95</span>)</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(librosf)</span></code></pre></div>
<pre><code>
Forecast method: Holt&#39;s method

Model Information:
Holt&#39;s method 

Call:
 holt(y = libros, h = 5, level = 95) 

  Smoothing parameters:
    alpha = 0.9513 
    beta  = 0.0001 

  Initial states:
    l = 41061.2751 
    b = 808.0212 

  sigma:  6342.639

     AIC     AICc      BIC 
545.6297 548.6297 551.9202 

Error measures:
                   ME    RMSE      MAE        MPE     MAPE      MASE       ACF1
Training set 1.059887 5834.38 4235.524 -0.1683705 6.717033 0.9155118 0.00362974

Forecasts:
     Point Forecast    Lo 95    Hi 95
2019       62930.86 50499.52 75362.21
2020       63738.89 46580.48 80897.29
2021       64546.91 43706.74 85387.08
2022       65354.93 41391.54 89318.33
2023       66162.96 39438.34 92887.57</code></pre>
<p>Los valores óptimos de los cuatro parámetros son <span class="math inline">\(\alpha=\)</span> 0.95, <span class="math inline">\(\beta=\)</span> 0, <span class="math inline">\(l_0 =\)</span> 41061.28 y <span class="math inline">\(b_0 =\)</span> 808.02. Observa que <span class="math inline">\(\alpha\)</span> es prácticamente 1 y que <span class="math inline">\(\beta\)</span> es cero. Si aplicamos estos valores de los parámetros a las ecuaciones recursivas y la predicción extra-muestral, obtenemos <span class="math inline">\(y_{T+h}=y_T + hb_0\)</span>: la predicción es el último valor observado más <span class="math inline">\(h\)</span> veces la primera pendiente estimada.</p>
<p>La calidad de las predicciones es razonable, con un error porcentual medio del 6.7%, y se ha mejorado respecto del alisado exponencial simple.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tail</span>(librosf<span class="sc">$</span>model<span class="sc">$</span>states, <span class="at">n =</span> <span class="dv">4</span>)</span></code></pre></div>
<pre><code>Time Series:
Start = 2015 
End = 2018 
Frequency = 1 
            l        b
2015 60809.31 808.1407
2016 59666.92 807.9356
2017 60199.13 807.9066
2018 62122.84 808.0240</code></pre>
<p>De nuevo, en el objeto <code>librosf</code> la matriz <code>librosf$model$states</code> guarda todos los valores obtenidos con las ecuaciones recursivas, en este caso el nivel y la pendiente, incluidos los valores de arranque. Puedes ver los valores de <span class="math inline">\(l_{2018}\)</span> y <span class="math inline">\(b_{2018}\)</span> en su última fila, que valen respectivamente 62122.84, 808.02. Así, la predicción para <span class="math inline">\(2019\)</span> es <span class="math inline">\(\widehat{y}_{2019}=l_{2018} + b_{2018}=\)</span> 62122.84 <span class="math inline">\(+\)</span> 808.02 <span class="math inline">\(=\)</span> 62930.86. Igualmente <span class="math inline">\(\widehat{y}_{2020}=l_{2018} + 2\cdot b_{2018}=\)</span> 63738.89. Es decir, el incremento entre previsiones es contante e igual a <span class="math inline">\(b_{2018}\)</span> que, por ser <span class="math inline">\(\beta\)</span> prácticamente nulo, coincide con <span class="math inline">\(b_0\)</span>.</p>
<p>La figura 2 muestra la serie Libros y las previsiones extra-muestrales que muestran una ligera tendencia creciente.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(librosf,</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>         <span class="at">xlab =</span> <span class="st">&quot;&quot;</span>,</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>         <span class="at">ylab =</span> <span class="st">&quot;Títulos&quot;</span>,</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>         <span class="at">main =</span> <span class="st">&quot;Figura 2. Libros y predicción con alisado de Holt&quot;</span>)</span></code></pre></div>
<p><img src="03-05-Tema5_files/figure-html/unnamed-chunk-6-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p><br />
<br />
</p>
</div>
</div>
<div id="alisado-exponencial-con-pendiente-amortiguada-ad-n" class="section level1" number="6">
<h1 number="6"><span class="header-section-number">6</span> Alisado exponencial con pendiente amortiguada (Ad, N)</h1>
<p>Las previsiones con el método de Holt presentan siempre una pendiente constante. En previsiones a corto plazo esto no es un problema, pero para previsiones a largo plazo la experiencia indica que suele aparecer un sesgo de previsión. El alisado exponencial con pendiente amortiguada trata de corregir esta limitación. El mecanismo, propuesto por Gardner y McKenzie en 1985, es introducir un nuevo parámetro <span class="math inline">\(0 \leq \phi \leq 1\)</span> que <em>amortigua</em> la tendencia hasta hacerla plana en el largo plazo.</p>
<p><br />
</p>
<div id="formulas-interactivas-de-sus-componentes-2" class="section level2" number="6.1">
<h2 number="6.1"><span class="header-section-number">6.1</span> Formulas interactivas de sus componentes</h2>
<p>Las <strong>ecuaciones recursivas</strong> son <span class="math display">\[
\begin{aligned}
l_t &amp; =\alpha y_t + (1-\alpha)(l_{t-1}+\phi b_{t-1}) \\
b_t &amp; =\beta (l_t - l_{t-1}) + (1-\beta)\phi b_{t-1} 
\end{aligned}
\]</span></p>
<p>La ecuación de la <strong>predicción intra-muestral</strong> a un periodo vista es <span class="math display">\[\widehat{y}_{t+1} = l_t + \phi b_t,\]</span> de forma que la ecuación de <strong>predicción extra-muestral</strong> es <span class="math display">\[\widehat{y}_{T+h}=l_T + (\phi + \phi^2 + \ldots + \phi^h) b_T.\]</span></p>
<p>Si <span class="math inline">\(\phi = 1\)</span>, se tiene el alisado de Holt y si <span class="math inline">\(\phi = 0\)</span>, se tiene el alisado simple. Para valores entre <span class="math inline">\(0\)</span> y <span class="math inline">\(1\)</span> en el corto plazo las predicciones tienen pendiente y en el largo plazo se hacen constantes e iguales a <span class="math inline">\(l_T + \phi b_T/(1 - \phi)\)</span>.</p>
<p><br />
</p>
</div>
<div id="ejemplo-2" class="section level2" number="6.2">
<h2 number="6.2"><span class="header-section-number">6.2</span> Ejemplo</h2>
<p>Vamos a usar el método de alisado con amortiguamiento para predecir, una vez más, la serie Libros añadiendo a la función <code>holt</code> el argumento <code>damped = TRUE</code>. Por razones prácticas el rango de búsqueda de <span class="math inline">\(\phi\)</span> queda en el intervalo <span class="math inline">\([0.8, 0.98]\)</span>. En este caso, para ver el efecto del <em>amortiguamiento</em> vamos a fijar el valor de <span class="math inline">\(\phi\)</span> a <span class="math inline">\(0.9\)</span> y vamos a pedir un horizonte temporal más largo.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>librosfd <span class="ot">&lt;-</span> <span class="fu">holt</span>(libros, <span class="at">damped =</span> <span class="cn">TRUE</span>, <span class="at">h =</span> <span class="dv">15</span>, <span class="at">phi =</span> <span class="fl">0.9</span>)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(librosfd)</span></code></pre></div>
<pre><code>
Forecast method: Damped Holt&#39;s method

Model Information:
Damped Holt&#39;s method 

Call:
 holt(y = libros, h = 15, damped = TRUE, phi = 0.9) 

  Smoothing parameters:
    alpha = 0.8885 
    beta  = 0.0001 
    phi   = 0.9 

  Initial states:
    l = 39515.4609 
    b = 4345.5669 

  sigma:  6337.754

     AIC     AICc      BIC 
544.3801 547.3801 550.6706 

Error measures:
                    ME     RMSE      MAE       MPE     MAPE      MASE
Training set -610.6056 5695.848 3943.135 -1.422026 6.229522 0.8523118
                   ACF1
Training set 0.00189887

Forecasts:
     Point Forecast    Lo 80    Hi 80    Lo 95     Hi 95
2019       62238.63 54116.47 70360.79 49816.86  74660.40
2020       62465.35 51599.92 73330.77 45848.12  79082.58
2021       62669.39 49625.05 75713.74 42719.79  82619.00
2022       62853.04 47944.62 77761.45 40052.58  85653.49
2023       63018.31 46454.06 79582.57 37685.47  88351.16
2024       63167.06 45097.88 81236.24 35532.64  90801.49
2025       63300.94 43842.72 82759.15 33542.17  93059.71
2026       63421.42 42666.80 84176.05 31679.96  95162.89
2027       63529.86 41555.06 85504.67 29922.30  97137.43
2028       63627.46 40496.65 86758.26 28251.94  99002.97
2029       63715.29 39483.49 87947.10 26655.95 100774.64
2030       63794.34 38509.37 89079.32 25124.31 102464.38
2031       63865.49 37569.42 90161.56 23649.12 104081.86
2032       63929.52 36659.77 91199.28 22224.03 105635.01
2033       63987.15 35777.26 92197.05 20843.84 107130.47</code></pre>
<p>La figura 3 muestra la serie Libros, su estimación (intra-muestral) y las predicciones a 15 años vista. Observa que la pendiente de las previsiones se <em>amortigua</em> en el tiempo, de forma que al principio las previsiones crecen más rápidamente que en los últimos años.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(librosfd,</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>         <span class="at">xlab =</span> <span class="st">&quot;&quot;</span>,</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>         <span class="at">ylab =</span> <span class="st">&quot;Títulos&quot;</span>,</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>         <span class="at">main =</span> <span class="st">&quot;Figura 3. Libros y predicción con alisado exponencial con amortiguamiento&quot;</span>,</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>         <span class="at">PI =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<p><img src="03-05-Tema5_files/figure-html/unnamed-chunk-8-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p><br />
<br />
</p>
</div>
</div>
<div id="alisado-de-holt-winters-aditivo-a-a-y-multiplicativo-a-m" class="section level1" number="7">
<h1 number="7"><span class="header-section-number">7</span> Alisado de Holt-Winters aditivo (A, A) y multiplicativo (A, M)</h1>
<p>El método de alisado exponencial de Holt-Winters es adecuado para una serie con tendencia y con estacionalidad. Existen dos versiones según que el esquema sea aditivo o multiplicativo.</p>
<p><br />
</p>
<div id="alisado-de-holt-winters-aditivo-a-a" class="section level2" number="7.1">
<h2 number="7.1"><span class="header-section-number">7.1</span> Alisado de Holt-Winters aditivo (A, A)</h2>
<p>Las <strong>ecuaciones recursivas</strong> de actualización son: <span class="math display">\[
\begin{aligned}
l_t &amp; =\alpha (y_t - s_{t-m} ) + (1-\alpha)(l_{t-1}+b_{t-1}) \\
b_t &amp; =\beta (l_t - l_{t-1}) + (1-\beta)b_{t-1} \\
s_t &amp; =\gamma (y_t - l_{t-1} - b_{t-1}) + (1 - \gamma)s_{t-m}
\end{aligned}
\]</span> con <span class="math inline">\(0 \leq \alpha, \beta, \gamma \leq 1\)</span>.</p>
<p>La ecuación de la <strong>predicción intra-muestral</strong> a un periodo vista es <span class="math display">\[\widehat{y}_{t+1}  = l_t + b_t + s_{t+1-m},\]</span> de forma que la ecuación de <strong>predicción extra-muestral es</strong>: <span class="math display">\[\widehat{y}_{T+h}=l_T + h b_T + s_{T+h - m(k+1)},\]</span> con <span class="math inline">\(k = \lfloor(h-1)/m\rfloor\)</span>.</p>
<p><br />
</p>
</div>
<div id="alisado-de-holt-winters-multiplicativo-a-m" class="section level2" number="7.2">
<h2 number="7.2"><span class="header-section-number">7.2</span> Alisado de Holt-Winters multiplicativo (A, M)</h2>
<p>Las <strong>ecuaciones recursivas</strong> de actualización son: <span class="math display">\[
\begin{aligned}
l_t &amp; =\alpha \frac{y_t}{s_{t-m}} + (1-\alpha)(l_{t-1}+b_{t-1}) \\
b_t &amp; =\beta (l_t - l_{t-1}) + (1-\beta)b_{t-1} \\
s_t &amp; =\gamma \frac{y_t}{l_{t-1} + b_{t-1}} + (1 - \gamma)s_{t-m}
\end{aligned}
\]</span></p>
<p>La ecuación de la <strong>predicción intra-muestral</strong> a un periodo vista es <span class="math display">\[\widehat{y}_{t+1}  = (l_t + b_t)s_{t+1-m},\]</span> de forma que la ecuación de <strong>predicción extra-muestral es</strong>: <span class="math display">\[\widehat{y}_{T+h}=(l_T + h b_T)s_{T+h - m(k+1)}.\]</span></p>
<p><br />
</p>
</div>
<div id="ejemplo-3" class="section level2" number="7.3">
<h2 number="7.3"><span class="header-section-number">7.3</span> Ejemplo</h2>
<p>Vamos a usar el método de Holt-Winters para predecir la serie Nacimientos, que presentaba un esquema multiplicativo. Para ello usaremos la función <code>hw</code> con el argumento <code>seasonal = "multiplicative"</code> (que sería <code>seasonal = "additive"</code> en caso de esquema aditivo). Vamos a considerar la serie Nacimientos desde enero de 2000 y pedir una previsión a dos años vista.</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>nacimientos <span class="ot">&lt;-</span> <span class="fu">read.csv2</span>(<span class="st">&quot;./series/nacimientos.csv&quot;</span>, <span class="at">header =</span> <span class="cn">TRUE</span>)</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>nacimientos <span class="ot">&lt;-</span> <span class="fu">ts</span>(nacimientos[, <span class="dv">2</span>],</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>                  <span class="at">start =</span> <span class="fu">c</span>(<span class="dv">1975</span>, <span class="dv">1</span>),</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>                  <span class="at">frequency =</span> <span class="dv">12</span>)</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>nacimientosb <span class="ot">&lt;-</span> <span class="fu">window</span>(nacimientos, <span class="at">start =</span> <span class="dv">2000</span>)</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>nacimientosbf <span class="ot">&lt;-</span> <span class="fu">hw</span>(nacimientosb, <span class="at">seasonal =</span> <span class="st">&quot;mult&quot;</span>, <span class="at">h =</span> <span class="dv">24</span>)</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(nacimientosbf)</span></code></pre></div>
<pre><code>
Forecast method: Holt-Winters&#39; multiplicative method

Model Information:
Holt-Winters&#39; multiplicative method 

Call:
 hw(y = nacimientosb, h = 24, seasonal = &quot;mult&quot;) 

  Smoothing parameters:
    alpha = 0.3892 
    beta  = 0.0148 
    gamma = 0.0425 

  Initial states:
    l = 33009.2785 
    b = 145.6544 
    s = 1.0025 0.9974 1.0527 1.0436 1.0281 1.0366
           0.9722 1.0146 0.9623 0.9901 0.9043 0.9958

  sigma:  0.023

     AIC     AICc      BIC 
4329.668 4332.583 4387.967 

Error measures:
                    ME     RMSE     MAE        MPE    MAPE      MASE      ACF1
Training set -74.07627 832.4718 662.566 -0.2262176 1.79118 0.4718897 0.0605442

Forecasts:
         Point Forecast    Lo 80    Hi 80    Lo 95    Hi 95
Jan 2019       30514.76 29617.09 31412.44 29141.88 31887.64
Feb 2019       27577.35 26701.93 28452.78 26238.50 28916.20
Mar 2019       30121.05 29094.43 31147.67 28550.97 31691.14
Apr 2019       29081.10 28021.40 30140.80 27460.42 30701.78
May 2019       30487.72 29304.26 31671.17 28677.78 32297.66
Jun 2019       29290.89 28083.51 30498.26 27444.37 31137.40
Jul 2019       31030.75 29676.27 32385.24 28959.25 33102.26
Aug 2019       30723.23 29306.62 32139.85 28556.71 32889.76
Sep 2019       30978.00 29472.49 32483.50 28675.53 33280.47
Oct 2019       31294.54 29694.70 32894.37 28847.80 33741.28
Nov 2019       29527.19 27942.21 31112.16 27103.17 31951.20
Dec 2019       29549.08 27886.35 31211.81 27006.15 32092.00
Jan 2020       29307.40 27570.10 31044.70 26650.43 31964.37
Feb 2020       26482.60 24842.63 28122.56 23974.48 28990.71
Mar 2020       28921.35 27052.66 30790.03 26063.44 31779.25
Apr 2020       27918.96 26038.95 29798.96 25043.73 30794.18
May 2020       29265.29 27213.70 31316.88 26127.65 32402.92
Jun 2020       28112.50 26062.87 30162.14 24977.86 31247.15
Jul 2020       29778.17 27522.36 32033.99 26328.20 33228.14
Aug 2020       29478.88 27160.65 31797.11 25933.45 33024.31
Sep 2020       29719.07 27294.94 32143.21 26011.68 33426.47
Oct 2020       30018.43 27480.73 32556.12 26137.36 33899.49
Nov 2020       28319.03 25839.72 30798.35 24527.25 32110.82
Dec 2020       28335.89 25768.57 30903.21 24409.51 32262.27</code></pre>
<p>Los valores óptimos de los parámetros son <span class="math inline">\(\alpha=\)</span> 0.39, <span class="math inline">\(\beta=\)</span> 0.01 y <span class="math inline">\(\gamma=\)</span> 0.04. Los valores tan bajos para <span class="math inline">\(\beta\)</span> y <span class="math inline">\(\gamma\)</span> indican que ambas, la pendiente y la estacionalidad, modifican su valor muy lentamente. Es decir, hay pendiente y hay efecto estacional, pero varían muy lentamente en el tiempo.</p>
<p>La calidad de las predicciones es notable, con un error porcentual medio del 1.8%. Recuerda que con el método ingenuo con estacionalidad el error era del 3.6%.</p>
<p>Los últimos valores de las componentes son</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>TT <span class="ot">&lt;-</span> <span class="fu">nrow</span>(nacimientosbf<span class="sc">$</span>model<span class="sc">$</span>states)</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>nacimientosbf<span class="sc">$</span>model<span class="sc">$</span>states[TT,]</span></code></pre></div>
<pre><code>        l         b        s1        s2        s3        s4        s5        s6 
30722.451  -100.998     1.001     0.997     1.053     1.039     1.027     1.034 
       s7        s8        s9       s10       s11       s12 
    0.973     1.009     0.959     0.990     0.904     0.997 </code></pre>
<p>Como el último dato de la serie es diciembre de 2018, los valores del nivel <span class="math inline">\(l\)</span> y la pendiente <span class="math inline">\(b\)</span> mostrados corresponden a ese periodo. Sin embargo, la componente estacional tiene un orden muy peculiar: s1 es el valor estacional para diciembre (mes del último dato), s2 el de noviembre, s3 de octubre, hasta s11 que sería febrero y s12 que es enero. Podemos reproducir las predicciones para los primeros 12 meses de enero a febrero con (ojo, el etiquetado de la salida no es correcto):</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>(nacimientosbf<span class="sc">$</span>model<span class="sc">$</span>states[TT, <span class="dv">1</span>] <span class="sc">+</span> (<span class="dv">1</span><span class="sc">:</span><span class="dv">12</span>)<span class="sc">*</span>nacimientosbf<span class="sc">$</span>model<span class="sc">$</span>states[TT, <span class="dv">2</span>]) <span class="sc">*</span> </span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>  nacimientosbf<span class="sc">$</span>model<span class="sc">$</span>states[TT, <span class="dv">14</span><span class="sc">:</span><span class="dv">3</span>]</span></code></pre></div>
<pre><code>     s12      s11      s10       s9       s8       s7       s6       s5 
30514.76 27577.35 30121.05 29081.10 30487.72 29290.89 31030.75 30723.23 
      s4       s3       s2       s1 
30978.00 31294.54 29527.19 29549.08 </code></pre>
<p>La figura 4 muestra la serie Nacimientos y las previsiones extra-muestrales.</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(nacimientosbf,</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>         <span class="at">xlab =</span> <span class="st">&quot;&quot;</span>,</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>         <span class="at">ylab =</span> <span class="st">&quot;Nacimientos&quot;</span>,</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>         <span class="at">main =</span> <span class="st">&quot;Figura 4. Nacimientos y predicción con alisado de Holt-Winters multiplicativo&quot;</span>,</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>         <span class="at">PI =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<p><img src="03-05-Tema5_files/figure-html/unnamed-chunk-13-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p><br />
<br />
</p>
</div>
</div>
<div id="ejemplo-con-transformación-logarítmica" class="section level1" number="8">
<h1 number="8"><span class="header-section-number">8</span> Ejemplo con transformación logarítmica</h1>
<p>Una alternativa a predecir la serie Nacimientos, que tiene esquema multiplicativo, es predecir la transformación logarítmica de la serie, que tendrá un esquema aditivo. Después, se aplica la transformación inversa y se obtienen las predicciones de la serie original.</p>
<p>Este proceso se puede realizar de forma sencilla y transparente con cualquiera de las funciones de alisado exponencial que hemos visto a partir de los argumentos <code>lambda</code> y <code>biasadj</code>.</p>
<ul>
<li><code>lambda = 0</code> indica a la función de alisado que se ha de realizar la transformación logarítmica de la serie. Es un parámetro de la transformación Box-Cox que comentaremos en el tema 6.</li>
<li><code>biasadj = TRUE</code> es necesario si tras una transformación de la serie original queremos que las predicciones sean insesgadas. Sea <span class="math inline">\(y_t\)</span> la serie original y <span class="math inline">\(z_t=log(y_t)\)</span> su transformación logarítmica. Si obtenemos una predicción <span class="math inline">\(\widehat{y}_t\)</span> de la serie original, esta será insesgada <span class="math inline">\(E[\widehat{y}_t]=y_t\)</span>. Ahora bien, si obtenemos una predicción <span class="math inline">\(\widehat{z}_t\)</span> de la serie transformada, podemos pensar que <span class="math inline">\(e^{\widehat{z}_t}\)</span> es una predicción insesgada de la serie original, pero resulta que <span class="math inline">\(E[e^{\widehat{z}_t}] \neq y_t\)</span>. Es decir, la exponencial de la predicción de la serie con transformada logarítmica no es insesgada. Si el argumento <code>biasadj</code> es fijado a FALSE, las predicciones se calcularán de forma directa deshaciendo la transformación y serán sesgadas; si es fijado a TRUE, las predicciones se calcularán por medio de una fórmula alternativa y serán insesgadas. En ambos casos las estimaciones son consistentes, así que para series largas no debería observarse mucha diferencia entre las dos alternativas.</li>
</ul>
<p>Vamos a practicar el uso de estos argumentos con la serie Nacimientos. Como se va a predecir el logaritmo de la serie, se debe indicar a la función <code>hw</code> que use el modelo Holt-Winters aditivo.</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>nacimientosbfl <span class="ot">&lt;-</span> <span class="fu">hw</span>(nacimientosb, </span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>                     <span class="at">seasonal =</span> <span class="st">&quot;addit&quot;</span>, </span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>                     <span class="at">h =</span> <span class="dv">24</span>, </span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>                     <span class="at">lambda =</span> <span class="dv">0</span>, </span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>                     <span class="at">biasadj =</span> <span class="cn">TRUE</span>)</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(nacimientosbfl)</span></code></pre></div>
<pre><code>
Forecast method: Holt-Winters&#39; additive method

Model Information:
Holt-Winters&#39; additive method 

Call:
 hw(y = nacimientosb, h = 24, seasonal = &quot;addit&quot;, lambda = 0,  

 Call:
     biasadj = TRUE) 

  Box-Cox transformation: lambda= 0 

  Smoothing parameters:
    alpha = 0.2611 
    beta  = 0.0478 
    gamma = 0.0001 

  Initial states:
    l = 10.4305 
    b = 0.0097 
    s = 0.0043 -0.0008 0.0526 0.0381 0.0245 0.0318
           -0.0282 0.01 -0.0338 -0.0047 -0.0961 0.0023

  sigma:  0.0246

      AIC      AICc       BIC 
-435.1078 -432.1936 -376.8090 

Error measures:
                   ME     RMSE      MAE        MPE     MAPE      MASE      ACF1
Training set -51.0673 885.7404 713.3606 -0.1736248 1.929193 0.5080665 0.2646703

Forecasts:
         Point Forecast    Lo 80    Hi 80    Lo 95    Hi 95
Jan 2019       30643.42 29685.38 31613.34 29195.06 32144.27
Feb 2019       27694.28 26788.35 28611.96 26325.44 29115.08
Mar 2019       30259.54 29214.19 31319.20 28681.11 31901.31
Apr 2019       29309.36 28231.72 30402.72 27683.51 31004.78
May 2019       30537.11 29335.00 31758.03 28725.20 32432.21
Jun 2019       29309.90 28069.48 30571.20 27442.29 31269.90
Jul 2019       31036.27 29620.72 32477.54 28907.57 33278.76
Aug 2019       30724.51 29212.67 32266.04 28454.02 33126.32
Sep 2019       31060.84 29411.90 32744.77 28588.01 33688.47
Oct 2019       31427.98 29629.37 33267.80 28734.81 34303.48
Nov 2019       29715.86 27885.00 31591.96 26978.83 32653.07
Dec 2019       29785.78 27813.47 31810.58 26842.30 32961.51
Jan 2020       29646.88 27541.13 31812.87 26509.83 33050.47
Feb 2020       26799.16 24761.67 28899.17 23769.40 30105.59
Mar 2020       29288.00 26909.63 31744.51 25758.10 33163.67
Apr 2020       28375.09 25919.20 30917.19 24737.31 32394.33
May 2020       29571.25 26849.15 32395.21 25547.33 34045.98
Jun 2020       28390.55 25616.78 31274.77 24298.78 32971.15
Jul 2020       30071.41 26959.40 33315.04 25490.46 35234.88
Aug 2020       29778.39 26520.45 33182.40 24993.09 35210.21
Sep 2020       30114.00 26637.35 33755.60 25018.83 35939.32
Oct 2020       30480.19 26773.45 34372.72 25060.14 36722.70
Nov 2020       28829.86 25142.93 32711.70 23451.24 35071.41
Dec 2020       28908.35 25026.90 33005.90 23259.27 35514.24</code></pre>
<p>Observa que en este caso la calidad de las predicciones (MAPE = 1.9%) es inferior a la obtenida con la serie sin transformar.</p>
<p>La figura 5 muestra la serie Nacimientos y las previsiones extra-muestrales obtenidas con y sin la transformación logarítmica.</p>
<p><img src="03-05-Tema5_files/figure-html/unnamed-chunk-15-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>La siguiente tabla muestra las predicciones de Nacimientos obtenidas sin transformar la serie, con transformación logarítmica y predicciones insesgadas (<code>biasadj = TRUE</code>), y con transformación logarítmica y predicciones sesgadas (<code>biasadj = FALSE</code>).</p>
<pre><code>         Sin transformar log(Nac) insesgadas log(Nac) sesgadas
Jan 2019        30514.76            30643.42          30634.19
Feb 2019        27577.35            27694.28          27685.14
Mar 2019        30121.05            30259.54          30248.39
Apr 2019        29081.10            29309.36          29297.12
May 2019        30487.72            30537.11          30522.48
Jun 2019        29290.89            29309.90          29293.65
Jul 2019        31030.75            31036.27          31016.26
Aug 2019        30723.23            30724.51          30701.42
Sep 2019        30978.00            31060.84          31033.63
Oct 2019        31294.54            31427.98          31395.92
Nov 2019        29527.19            29715.86          29680.66
Dec 2019        29549.08            29785.78          29744.96</code></pre>
<p>Observa que las predicciones sesgadas son menores que las insesgadas. Esto siempre es así. La diferencia depende fundamentalmente de la varianza del error, <em>sigma</em> al cuadrado en la salida de los métodos de alisado exponencial. Cuanto mayor es la varianza del error, mayores son las diferencias.</p>
<p>Por otro lado, las predicciones obtenidas sin y con la transformación logarítmica no guardan ninguna relación.</p>
<p><strong>Ni la transformación logarítmica ni el uso de predicciones insesgadas aseguran mejores predicciones respecto de otras opciones</strong>, como pueden ser trabajar con predicciones sesgadas o no realizar la transformación logarítmica.</p>
<p><br />
<br />
</p>
</div>
<div id="casos-generales-de-alisado-exponencial" class="section level1" number="9">
<h1 number="9"><span class="header-section-number">9</span> Casos generales de alisado exponencial</h1>
<p>En los epígrafes previos hemos visto cinco de los casos expuestos en la taxonomía del epígrafe 3, y las funciones de <code>R</code> asociadas. Veamos ahora como estimar cualquiera de los quince modelos que surgen según las diferentes posibilidades de la tendencia (N, A, Ad, M y Md) y de la estacionalidad (N, A y M).</p>
<p>Recordemos que al añadir el error, aditivo o multiplicativo, estos quince modelos se convierten en treinta. Sin embargo, el tipo de error no influye en el cálculo de las previsiones, solo influye en el cálculo del intervalo de confianza de estas.</p>
<p><br />
</p>
<div id="la-función-ets" class="section level2" number="9.1">
<h2 number="9.1"><span class="header-section-number">9.1</span> La función <code>ets</code></h2>
<p>Podemos estimar cualquiera de los treinta modelos usando la función <code>ets</code> del paquete <code>forecast</code>. A diferencia de las funciones previas <code>ses</code>, <code>holt</code> y <code>hw</code>, la función <code>ets</code> solo estima los modelos, pero no produce predicciones. Para ello habrá que usar la función <code>forecast</code> sobre un modelo estimado con <code>ets</code>. Mira la ayuda para ver una explicación detallada de los argumentos de estas funciones.</p>
<ul>
<li>El tipo de modelo en <code>ets</code> se especifica con el argumento <code>model</code>, un código de tres letras indicando el tipo de Error, Tendencia y eStacionalidad (ETS). Por ejemplo, <code>model = "ANN"</code> indica un modelo con error aditivo, sin tendencia ni estacionalidad, es decir, el alisado exponencial simple; <code>model = "AAN"</code> indica un modelo con error aditivo, pendiente aditiva, pero sin estacionalidad, el alisado exponencial de Holt. El alisado exponencial de Holt-Winters multiplicativo sería <code>model = "AAM"</code>.</li>
<li>Si se desea incluir amortiguamiento, hay que incluir el argumento <code>damped = TRUE</code>.</li>
<li>Por defecto <code>ets</code> no considera modelos con tendencia multiplicativa (últimas dos líneas de la taxonomía del epígrafe 3). Debes fijar el parámetro <code>allow.multiplicative.trend=TRUE</code> para contemplar esta opción.</li>
<li>Además, se sigue disponiendo de los argumentos <code>lambda</code> y <code>biasadj</code>.</li>
</ul>
<p><strong>Criterios de optimización</strong></p>
<p>Fijado un modelo, <code>ets</code> estima por defecto sus parámetros maximizando la función de verosimilitud. Esta búsqueda esta restringida a <span class="math inline">\(0 &lt; \beta &lt; \alpha &lt; 1\)</span>, <span class="math inline">\(0 &lt; \gamma &lt; 1 - \alpha\)</span> y <span class="math inline">\(0.8 &lt; \phi &lt; 0.98\)</span>. Es decir, los tres primeros parámetros nunca pueden ser 0 o 1, y en la práctica sus valores límite son 0.0001 y 0.9999.</p>
<p>Puedes cambiar el criterio de optimización con el argumento <code>opt.crit</code>. Por defecto vale “lik”, pero si lo fijas a <code>opt.crit = "mse"</code> se estiman los parámetros que minimizan el error cuadrático medio. Otra opción interesante es <code>opt.crit = "amse"</code> que minimiza la media de los errores cuadráticos medios obtenido sobre las previsiones hasta <code>nmse</code> periodos vista. En este caso usa el argumento <code>nmse</code> para fijar el valor numérico del horizonte temporal.</p>
<p><strong>Selección de modelos</strong></p>
<p>Lo más habitual es no saber cual es el mejor modelo, entendiendo como tal, el que mejor se ajusta a la serie temporal. De hecho, si lo que buscamos es predecir bien, más que entender la naturaleza del proceso generador de datos, el mejor modelo será el que mejor prediga.</p>
<p>Si en una de las tres letras del código del modelo se indica “Z”, la función <code>ets</code> selecciona de entre los modelos posibles el que mejor se ajusta. Por ejemplo, <code>model = "AAZ"</code> indica un modelo con error y pendiente aditivos y dejaría a <code>ets</code> la búsqueda de la mejor opción para la estacionalidad (aditiva o multiplicativa). Si se especifica <code>model = "ZZZ</code> junto con <code>damped = NULL</code> (opciones por defecto) se dejaría a la función total libertad para buscar entre todos los modelos (excepto aquellos con pendiente multiplicativa). Si se desea restringir la búsqueda a modelos sin amortiguamiento basta indicar <code>damped = FALSE</code> y si se desea restringir la búsqueda solo a modelos aditivos se puede usar el argumento <code>additive.only = TRUE</code>.</p>
<p>Queda pendiente saber que criterio se usa para seleccionar el modelo cuando se ofrece esta opción. Esto se hace a partir de un criterio de información entre Akaike (aic), Akaike corregido para pequeñas muestras (aicc) y el Bayesiano (bic). Sus fórmulas son: <span class="math display">\[aic = -2log(L) + 2k\]</span> <span class="math display">\[aicc = aic + \frac{k(k+1)}{T-k-1}\]</span> <span class="math display">\[bic=aic + k(log(T) - 2)\]</span> donde <span class="math inline">\(L\)</span> es la verosimilitud, <span class="math inline">\(T\)</span> el número de datos y <span class="math inline">\(k\)</span> el de parámetros estimados (incluidos los puntos iniciales de arranque y la varianza residual).</p>
<p>Por defecto se usa Akaike corregido para pequeñas muestras, pero el argumento <code>ic</code> permite cambiar de criterio.</p>
<p><br />
</p>
</div>
<div id="una-reflexión-sobre-los-métodos-automáticos-de-selección-de-modelos" class="section level2" number="9.2">
<h2 number="9.2"><span class="header-section-number">9.2</span> Una reflexión sobre los métodos automáticos de selección de modelos</h2>
<p>Con el comando <code>forecast(ets(nacimientos), h = 24)</code> obtenemos una predicción mensual a dos años vista del número de nacimientos en España. Así de simple, solo 31 caracteres. Todo esto gracias a que un algoritmo interno ha estimado los parámetros de múltiples modelos, elegido el mejor modelo de todos y lo ha usado para obtener las predicciones. Podemos afirmar que tenemos las mejores predicciones. Un momento, ¿podemos?</p>
<p>Parémonos a reflexionar sobre lo que hemos hecho o, más bien, lo que el algoritmo ha hecho y a contrastarlo con lo que nosotros queríamos. Por un lado, el algoritmo estima los parámetros de un menú fijo de modelos y para ello usa un criterio de optimización, que por defecto es maximizar la función de verosimilitud; cuando ya tiene estimados todos los modelos, elije el mejor usando el criterio de información de Akaike corregido para muestras pequeñas; y finalmente, nosotros medimos la capacidad predictiva del modelo seleccionado usando el error absoluto porcentual medio. Vaya, resulta que en los procesos de identificación y estimación del mejor modelo se usan dos criterios diferentes, que además no coinciden con nuestro criterio de calidad de las predicciones.</p>
<p>Si consideramos que la calidad de un modelo viene dada por el error absoluto porcentual medio en las predicciones intra-muestrales a un periodo vista (lo que hemos decidido llamar MAPE), ¿no deberíamos estimar los parámetros del modelo usando como criterio la minimización del MAPE?, ¿no deberíamos elegir entre varios modelos aquel que presenta un MAPE menor? De esta forma, en todos los pasos del proceso se usa el mismo criterio, que es, además, el criterio que hemos considerado adecuado para valorar la calidad de las predicciones.</p>
<p>Pero no es esto lo que hacemos.</p>
<p>Nada nos garantiza que el modelo estimado y seleccionado por el algoritmo estime las mejores predicciones posibles. Y por <em>mejores</em> quiero decir que de entre todos los posibles modelos del menú y todos los posibles valores de sus parámetros, el seleccionado sea que el minimiza nuestro criterio de calidad de las predicciones.</p>
<p>Ahora ya podemos dar respuesta a la pregunta del primer párrafo: no, no podemos afirmar que nuestras predicciones sean las mejores.</p>
<p>Alguien dirá que casi seguro entre las predicciones sub-óptimas obtenidas por el algoritmo con su extraña mezcla de criterios y las predicciones óptimas de verdad no habrá mucha diferencia. Total, que más da una función de verosimilitud que un criterio de información que una medida del error medio. Pero lo cierto es que no lo sabemos, no tenemos ni idea de la distancia que hay entre lo óptimo y lo sub-óptimo, y si el coste de equivocarme en las predicciones es alto, puede que incluso una pequeña diferencia sea relevante.</p>
<p>Esta reflexión realizada en el contexto de series temporales y para la función <code>ets</code> es aplicable a todos los casos donde dejamos que un algoritmo ya programado elija el mejor modelo, y se basa en el hecho de que rara vez los criterios de estimación y elección que usan los algoritmos coinciden con el concepto de calidad de ajuste que estamos interesados</p>
<p>A pesar de lo aquí expuesto, como es más cómodo (y rápido) tirar de rutinas ya programadas que escribir tu propio código, seguiremos trabajando con modelos sub-óptimos y obteniendo estimaciones sub-óptimas, pero diciendo que son las mejores.</p>
<p><br />
</p>
</div>
<div id="residuo-aditivo-versus-residuo-multiplicativo" class="section level2" number="9.3">
<h2 number="9.3"><span class="header-section-number">9.3</span> Residuo aditivo versus residuo multiplicativo</h2>
<p>En los modelos de alisado estimados por la función <code>ets</code> la fórmula para el cálculo del residuo estimado depende de su naturaleza aditiva o multiplicativa.</p>
<p>Si el <strong>residuo es aditivo</strong>, entonces el modelo es <span class="math inline">\(y_t = \widehat{y}_t + \widehat{\varepsilon}_t\)</span> y el residuo se define de la forma usual <span class="math display">\[\widehat{\varepsilon}_t = y_t - \widehat{y}_t.\]</span> Ahora bien, si el <strong>residuo es multiplicativo</strong>, entonces el modelo es <span class="math inline">\(y_t = \widehat{y}_t \cdot (1 + \widehat{\varepsilon}_t)\)</span>, y no <span class="math inline">\(y_t = \widehat{y}_t \cdot \widehat{\varepsilon}_t\)</span>, como se podría esperar. Por tanto, el residuo multiplicativo se define como <span class="math display">\[\varepsilon_t = (y_t - \widehat{y}_t)/\widehat{y}_t.\]</span> De esta forma en ambos casos el residuo evoluciona alrededor del valor 0 y se le pueden imponer las hipótesis usuales de ruido blanco.</p>
<p>La función <code>residual</code> permite extraer de un objeto <code>ets</code> el residuo del modelo. Si el modelo tiene residuo multiplicativo y se desea obtener el residuo aditivo, se debe usar con el argumento <code>type = "response"</code>.</p>
<p><br />
<br />
</p>
</div>
</div>
<div id="ejemplos-de-aplicación" class="section level1" number="10">
<h1 number="10"><span class="header-section-number">10</span> Ejemplos de aplicación</h1>
<p><br />
</p>
<div id="libros" class="section level2" number="10.1">
<h2 number="10.1"><span class="header-section-number">10.1</span> Libros</h2>
<div id="identificación-y-estimación-del-mejor-modelo" class="section level3 unnumbered">
<h3 class="unnumbered">Identificación y estimación del mejor modelo</h3>
<p>Si estimamos el mejor modelo de alisado exponencial para la serie Libros sin ningún tipo de restricción, nos encontramos:</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>librosEts <span class="ot">&lt;-</span> <span class="fu">ets</span>(libros)</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(librosEts) </span></code></pre></div>
<pre><code>ETS(M,N,N) 

Call:
 ets(y = libros) 

  Smoothing parameters:
    alpha = 0.9999 

  Initial states:
    l = 40449.9278 

  sigma:  0.0919

     AIC     AICc      BIC 
536.4611 537.5520 540.2354 

Training set error measures:
                   ME     RMSE      MAE      MPE    MAPE      MASE       ACF1
Training set 835.8489 5896.169 4460.311 1.251566 7.04867 0.9640998 -0.0393776</code></pre>
<p>El modelo estimado es ETS(M,N,N) o “MNN”, un modelo sin pendiente ni estacionalidad y con error multiplicativo. Es decir, <span class="math inline">\(y_{t+1} = l_t \cdot (1 + \varepsilon_{t+1})\)</span>.</p>
<p>El valor de <span class="math inline">\(\alpha\)</span> técnicamente es 1, indicando que el nivel de la serie varia en el tiempo y que realmente estamos usando para las previsiones el método ingenuo I.</p>
<p>Respecto de la calidad del modelo, el valor de MAPE= <span class="math inline">\(7\)</span>% evidencia que estamos ante un modelo que ajusta razonablemente bien a los datos, y MASE= <span class="math inline">\(0.96\)</span> indica que el modelo de alisado exponencial simple reduce en solo un <span class="math inline">\(4\)</span>% el error del método ingenuo I.</p>
</div>
<div id="predicción" class="section level3 unnumbered">
<h3 class="unnumbered">Predicción</h3>
<p>Mediante la función <code>forecast</code> podemos predecir los casos de Libros. Por tratarse de un modelo sin pendiente ni estacionalidad, la predicción es constante en el tiempo (véase figura 6).</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>librosEtsPre <span class="ot">&lt;-</span> <span class="fu">forecast</span>(librosEts, <span class="at">h =</span> <span class="dv">5</span>)</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>librosEtsPre</span></code></pre></div>
<pre><code>     Point Forecast    Lo 80    Hi 80    Lo 95    Hi 95
2019        62179.8 54859.93 69499.66 50985.03 73374.56
2020        62179.8 51806.66 72552.93 46315.46 78044.14
2021        62179.8 49448.76 74910.83 42709.36 81650.24
2022        62179.8 47448.33 76911.26 39649.96 84709.63
2023        62179.8 45674.75 78684.84 36937.51 87422.08</code></pre>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(librosEtsPre,</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>         <span class="at">xlab =</span> <span class="st">&quot;&quot;</span>,</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>         <span class="at">ylab =</span> <span class="st">&quot;Títulos&quot;</span>,</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>         <span class="at">main =</span> <span class="st">&quot;Figura 6. Libros y predicción a 5 años vista&quot;</span>)</span></code></pre></div>
<p><img src="03-05-Tema5_files/figure-html/unnamed-chunk-18-1.png" width="80%" style="display: block; margin: auto;" /></p>
</div>
<div id="análisis-del-error" class="section level3 unnumbered">
<h3 class="unnumbered">Análisis del error</h3>
<p>El error de un modelo de alisado <em>contiene</em> la componente de <strong>Intervención</strong> y el propio término de <strong>Error</strong>. Ver numérica o gráficamente el error permite identificar fácilmente la presencia de valores atípicos (intervención).</p>
<p>El modelo de alisado tiene error multiplicativo así que vamos a usar el argumento <code>type = "response"</code> para obtener el error aditivo con <code>residuals</code>.</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>error <span class="ot">&lt;-</span> <span class="fu">residuals</span>(librosEts, <span class="at">type =</span> <span class="st">&quot;response&quot;</span>)</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>sderror <span class="ot">&lt;-</span> <span class="fu">sd</span>(error)</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(error, <span class="at">series=</span><span class="st">&quot;Error&quot;</span>,</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>         <span class="at">colour =</span> <span class="st">&quot;black&quot;</span>,</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>         <span class="at">xlab =</span> <span class="st">&quot;Periodo&quot;</span>,</span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>         <span class="at">ylab =</span> <span class="st">&quot;Error&quot;</span>,</span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>         <span class="at">main =</span> <span class="st">&quot;Figura 7: Error + Intervención&quot;</span>) <span class="sc">+</span></span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">3</span>, <span class="sc">-</span><span class="dv">2</span>, <span class="dv">2</span> ,<span class="dv">3</span>)<span class="sc">*</span>sderror, </span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a>             <span class="at">colour =</span> <span class="fu">c</span>(<span class="st">&quot;red&quot;</span>, <span class="st">&quot;blue&quot;</span>, <span class="st">&quot;blue&quot;</span>, <span class="st">&quot;red&quot;</span>), <span class="at">lty =</span> <span class="dv">2</span>) <span class="sc">+</span> </span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="at">breaks=</span> <span class="fu">seq</span>(<span class="dv">1993</span>, <span class="dv">2019</span>, <span class="dv">2</span>)) </span></code></pre></div>
<p><img src="03-05-Tema5_files/figure-html/unnamed-chunk-19-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>La figura 7 muestra que aunque algún error supera las dos desviaciones típicas, ninguno puede ser considerado como claramente atípico.</p>
</div>
<div id="validación-error-extra-muestral-a-varios-periodos-vista" class="section level3 unnumbered">
<h3 class="unnumbered">Validación: error extra-muestral a varios periodos vista</h3>
<p>Vamos a mejorar la estimación de la calidad de las predicciones obteniendo el MAPE para <strong>previsiones extra-muestrales a varios periodos vista</strong>. Para ello vamos a reservar, por ejemplo, las últimas 6 observaciones de la serie Libros y ajustar el modelo con las restantes. Después usaremos este modelo para calcular las predicciones a 6 periodos vista y compararlas con los valores reales de la serie Libros.</p>
<p>Recuerda, este método para valorar la calidad de las predicciones usa la filosofía del método <em>training set/test set</em>: el periodo de datos usado en la estimación no se usa como periodo de datos para la validación. Sin embargo, tiene el problema de que el error obtenido es una mezcla de errores de predicción a corto, medio y largo plazo difícil de valorar. Además, los resultados dependen tremendamente del punto de corte temporal seleccionado.</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Definimos las observaciones intra- y extra-muestrales</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>librosIntra <span class="ot">&lt;-</span> <span class="fu">subset</span>(libros, <span class="at">end =</span> <span class="fu">length</span>(libros) <span class="sc">-</span> <span class="dv">6</span>)</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>librosExtra <span class="ot">&lt;-</span> <span class="fu">subset</span>(libros, <span class="at">start =</span> <span class="fu">length</span>(libros) <span class="sc">-</span> <span class="dv">5</span>)</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Estimamos el modelo con todos los datos menos los 6 ultimos</span></span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>librosIntraEts <span class="ot">&lt;-</span> <span class="fu">ets</span>(librosIntra, <span class="at">model =</span> <span class="st">&quot;MNN&quot;</span>)</span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Predecimos los 6 años que hemos quitado de la serie y </span></span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a><span class="co"># vemos la calidad del ajuste.</span></span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a>librosExtraPre <span class="ot">&lt;-</span> <span class="fu">forecast</span>(librosIntraEts, <span class="at">h =</span> <span class="dv">6</span>)</span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a><span class="fu">accuracy</span>(librosExtraPre, librosExtra)</span></code></pre></div>
<pre><code>                     ME     RMSE       MAE        MPE      MAPE      MASE
Training set   1462.163  5905.05  4665.937   2.339602  7.216588 0.9533584
Test set     -10434.291 10678.54 10434.291 -17.790750 17.790750 2.1319661
                   ACF1 Theil&#39;s U
Training set -0.1925569        NA
Test set      0.2260149  3.937573</code></pre>
<p>Atendiendo al MAPE se tiene que el error de <strong>previsión a un periodo vista</strong> en el <strong>periodo intra-muestral</strong> de <strong>1993 a 2012</strong> es del 7.2%; mientras que el error de <strong>previsión a largo plazo</strong> en el <strong>periodo extra-muestral</strong> de <strong>2013 a 2018</strong> es del 17.8%. Ademas, para el periodo extra-muestral el error medio (ME) es negativo y muy elevado, un indicativo de que las previsiones están segadas. En resumen, la calidad del modelo se deteriora muy rápidamente en cuanto nos salimos de las condiciones óptimas.</p>
<p>Un gráfico puede ayudar a entender este proceso de validación. En la figura 10:</p>
<ul>
<li>La línea de puntos vertical separa el periodo muestral (1993-2012) usado para estimar el modelo, del periodo extra-muestral (2013-2018) usado sólo para hacer las previsiones.</li>
<li>La serie Libros aparece como una línea sólida en negro, desde 1993 hasta 2018.</li>
<li>La previsión <em>intra</em>-muestral (a un periodo vista) de la serie Libros aparece como una línea azul.</li>
<li>La línea en rojo es la previsión <em>extra</em>-muestral a largo plazo: <span class="math inline">\(\hat{y}_{T+h}=l_T\)</span>, donde <span class="math inline">\(T=2012\)</span>. Observa que todas las previsiones están por encima del valor real de la serie.</li>
<li>Al lado de cada previsión se ha indicado el error estimado (MAPE).</li>
</ul>
<p>Claramente estos resultados dependen del punto de corte seleccionado.</p>
<p><img src="03-05-Tema5_files/figure-html/unnamed-chunk-22-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p><strong>Nota:</strong> La presencia de tendencia, primero creciente y luego decreciente, en la serie Libros puede hacernos pensar que un modelo más adecuado para su ajuste y predicción sería ETS(M,A,N), forzando a que haya pendiente. De hecho, el error de estimación de este modelo es del 6%, frente al 7% para el modelo ETS(M,N,N). Sin embargo, el error de previsión extra-muestral a largo plazo para el modelo ETS(M,A,N) es del 31.5%, frente al 17.8% para el modelo ETS(M,N,N). <strong>Mejor ajuste no implica mejor predicción.</strong> De nuevo, incidir en que claramente estos resultados dependen del punto de corte seleccionado.</p>
<p><br />
</p>
</div>
</div>
<div id="nacimientos" class="section level2" number="10.2">
<h2 number="10.2"><span class="header-section-number">10.2</span> Nacimientos</h2>
<p>Veamos un segundo ejemplo con la serie Nacimientos (desde el año 2000).</p>
<div id="identificación-y-estimación-del-mejor-modelo-1" class="section level3 unnumbered">
<h3 class="unnumbered">Identificación y estimación del mejor modelo</h3>
<p>Si damos total libertad al proceso de selección del mejor modelo, el óptimo tiene tendencia amortiguada con un parámetro <span class="math inline">\(\phi = 0.98\)</span>, su máximo valor permitido. Este resultado aconseja repetir el proceso de selección del modelo restringido a aquellos sin amortiguamiento.</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>nacimientosEts <span class="ot">&lt;-</span> <span class="fu">ets</span>(nacimientosb, <span class="at">damped =</span> <span class="cn">FALSE</span>)</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(nacimientosEts) </span></code></pre></div>
<pre><code>ETS(M,A,A) 

Call:
 ets(y = nacimientosb, damped = FALSE) 

  Smoothing parameters:
    alpha = 0.453 
    beta  = 0.0129 
    gamma = 0.0001 

  Initial states:
    l = 33060.0131 
    b = 133.8359 
    s = 186.0139 -23.5386 1964.614 1476.782 838.1165 1139.429
           -1049.547 364.3884 -1322.119 -197.631 -3356.247 -20.2609

  sigma:  0.0226

     AIC     AICc      BIC 
4323.210 4326.124 4381.509 

Training set error measures:
                   ME     RMSE      MAE        MPE     MAPE      MASE
Training set -78.9317 819.2494 647.6997 -0.2429001 1.751808 0.4613018
                    ACF1
Training set -0.01764952</code></pre>
<p>El modelo estimado es ETS(M,A,A), es decir, <span class="math inline">\(y_{t+1} = (l_t + b_t + s_{t+1-m}) \cdot (1+ \varepsilon_{t+1})\)</span>.</p>
<p>El bajo valor de <span class="math inline">\(\beta\)</span> y <span class="math inline">\(\gamma\)</span> indican que ambas, la pendiente y la estacionalidad, varían muy lentamente en el tiempo (véase la figura 9).</p>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(nacimientosEts,</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>         <span class="at">xlab =</span> <span class="st">&quot;Periodo&quot;</span>,</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>         <span class="at">main =</span> <span class="st">&quot;Figura 9. Componentes del modelo óptimo para Nacimientos&quot;</span>)</span></code></pre></div>
<p><img src="03-05-Tema5_files/figure-html/unnamed-chunk-24-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>Respecto de la calidad del modelo, el MAPE de 1.8% indica que estamos ante un modelo que se ajusta muy bien a los datos; y el valor de MASE igual a 0.46 indica que este modelo reduce en un 54% el error del método ingenuo con estacionalidad, el más sencillo posible.</p>
<p>Podemos ver los últimos valores estimados del nivel, la pendiente y la estacionalidad para interpretarlos.</p>
<div class="sourceCode" id="cb35"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>TT <span class="ot">&lt;-</span> <span class="fu">nrow</span>(nacimientosEts<span class="sc">$</span>states)</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>nacimientosEts<span class="sc">$</span>states[TT,]</span></code></pre></div>
<pre><code>       l        b       s1       s2       s3       s4       s5 
30579.27   -97.62   185.84   -23.71  1964.49  1476.46   838.07 </code></pre>
<pre><code>      s6       s7       s8       s9      s10      s11      s12 
 1139.30 -1049.77   364.26 -1322.26  -197.71 -3356.56   -20.23 </code></pre>
<p>También podemos usarlos para predecir un año:</p>
<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>nacimientosEts<span class="sc">$</span>states[TT, <span class="dv">1</span>] <span class="sc">+</span> (<span class="dv">1</span><span class="sc">:</span><span class="dv">12</span>) <span class="sc">*</span> nacimientosEts<span class="sc">$</span>states[TT, <span class="dv">2</span>] <span class="sc">+</span> </span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>  nacimientosEts<span class="sc">$</span>states[TT, <span class="dv">14</span><span class="sc">:</span><span class="dv">3</span>]</span></code></pre></div>
<pre><code>     s12      s11      s10       s9       s8       s7       s6       s5 
30461.42 27027.46 30088.70 28866.53 30455.42 28943.77 31035.22 30636.37 
      s4       s3       s2       s1 
31177.13 31567.54 29481.72 29593.65 </code></pre>
<p>Febrero es el mes con menor número de nacimientos: nacen 3356 bebés menos, respecto de la media anual. En octubre es cuando más niños nacen: 1964 más que la media anual.</p>
<p>Nuestra predicción para enero de 2019 es de 30461 bebés y para diciembre de 2019 de 29593 bebés.</p>
</div>
<div id="predicción-1" class="section level3 unnumbered">
<h3 class="unnumbered">Predicción</h3>
<p>Si pedimos los valores de predicción tenemos (sólo se muestran los primeros meses):</p>
<div class="sourceCode" id="cb40"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>nacimientosEtsPre <span class="ot">&lt;-</span> <span class="fu">forecast</span>(nacimientosEts, <span class="at">h =</span> <span class="dv">24</span>, <span class="at">level =</span> <span class="dv">95</span>)</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>nacimientosEtsPre</span></code></pre></div>
<pre><code>         Point Forecast    Lo 95    Hi 95
Jan 2019       30461.42 29110.45 31812.39
Feb 2019       27027.46 25673.56 28381.37
Mar 2019       30088.70 28504.04 31673.36
Apr 2019       28866.53 27194.30 30538.76
May 2019       30455.42 28611.33 32299.52</code></pre>
<p>Gráficamente,</p>
<div class="sourceCode" id="cb42"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(nacimientosEtsPre,</span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>         <span class="at">xlab =</span> <span class="st">&quot;&quot;</span>,</span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>         <span class="at">ylab =</span> <span class="st">&quot;Bebés&quot;</span>,</span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a>         <span class="at">main =</span> <span class="st">&quot;Figura 10. Nacimientos y predicción&quot;</span>)</span></code></pre></div>
<p><img src="03-05-Tema5_files/figure-html/unnamed-chunk-31-1.png" width="80%" style="display: block; margin: auto;" /></p>
</div>
<div id="análisis-del-error-1" class="section level3 unnumbered">
<h3 class="unnumbered">Análisis del error</h3>
<p>El modelo de alisado tiene error multiplicativo así que debemos usar el argumento <code>type = "response"</code> para obtener el error aditivo con <code>residuals</code>.</p>
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>error <span class="ot">&lt;-</span> <span class="fu">residuals</span>(nacimientosEts, <span class="at">type =</span> <span class="st">&quot;response&quot;</span>)</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>sderror <span class="ot">&lt;-</span> <span class="fu">sd</span>(error)</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(error, <span class="at">series=</span><span class="st">&quot;Error&quot;</span>,</span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a>         <span class="at">colour =</span> <span class="st">&quot;black&quot;</span>,</span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a>         <span class="at">xlab =</span> <span class="st">&quot;Periodo&quot;</span>,</span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a>         <span class="at">ylab =</span> <span class="st">&quot;Error&quot;</span>,</span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a>         <span class="at">main =</span> <span class="st">&quot;Figura 11: Error + Intervención&quot;</span>) <span class="sc">+</span></span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">3</span>, <span class="sc">-</span><span class="dv">2</span>, <span class="dv">2</span> ,<span class="dv">3</span>)<span class="sc">*</span>sderror, </span>
<span id="cb43-10"><a href="#cb43-10" aria-hidden="true" tabindex="-1"></a>             <span class="at">colour =</span> <span class="fu">c</span>(<span class="st">&quot;red&quot;</span>, <span class="st">&quot;blue&quot;</span>, <span class="st">&quot;blue&quot;</span>, <span class="st">&quot;red&quot;</span>), <span class="at">lty =</span> <span class="dv">2</span>) <span class="sc">+</span> </span>
<span id="cb43-11"><a href="#cb43-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="at">breaks=</span> <span class="fu">seq</span>(<span class="dv">2000</span>, <span class="dv">2019</span>, <span class="dv">2</span>)) </span></code></pre></div>
<p><img src="03-05-Tema5_files/figure-html/unnamed-chunk-32-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>Se identifica un valor claramente atípico –supera las 4 desviaciones típicas– que corresponde a enero de 2011. Abril de 2008 es otro candidato a intervención por alcanzar las 3 desviaciones típicas.</p>
</div>
<div id="validación-error-extra-muestral-según-horizonte-temporal" class="section level3 unnumbered">
<h3 class="unnumbered">Validación: error extra-muestral según horizonte temporal</h3>
<p>En este ejemplo calcularemos el error extra-muestral según el horizonte temporal de previsión, una metodología que ya hemos visto anteriormente.</p>
<div class="sourceCode" id="cb44"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>k <span class="ot">&lt;-</span> <span class="dv">120</span>                 </span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>h <span class="ot">&lt;-</span> <span class="dv">12</span>                  </span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a>TT <span class="ot">&lt;-</span> <span class="fu">length</span>(nacimientosb)</span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a>s <span class="ot">&lt;-</span> TT <span class="sc">-</span> k <span class="sc">-</span> h </span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a>mapeAlisado <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="cn">NA</span>, s <span class="sc">+</span> <span class="dv">1</span>, h)</span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">0</span><span class="sc">:</span>s) {</span>
<span id="cb44-8"><a href="#cb44-8" aria-hidden="true" tabindex="-1"></a>  train.set <span class="ot">&lt;-</span> <span class="fu">subset</span>(nacimientosb, <span class="at">start =</span> i <span class="sc">+</span> <span class="dv">1</span>, <span class="at">end =</span> i <span class="sc">+</span> k)</span>
<span id="cb44-9"><a href="#cb44-9" aria-hidden="true" tabindex="-1"></a>  test.set <span class="ot">&lt;-</span>  <span class="fu">subset</span>(nacimientosb, <span class="at">start =</span> i <span class="sc">+</span> k <span class="sc">+</span> <span class="dv">1</span>, <span class="at">end =</span> i <span class="sc">+</span> k <span class="sc">+</span> h)</span>
<span id="cb44-10"><a href="#cb44-10" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb44-11"><a href="#cb44-11" aria-hidden="true" tabindex="-1"></a>  fit <span class="ot">&lt;-</span> <span class="fu">ets</span>(train.set, <span class="at">model =</span> <span class="st">&quot;MAA&quot;</span>, <span class="at">damped =</span> <span class="cn">FALSE</span>)</span>
<span id="cb44-12"><a href="#cb44-12" aria-hidden="true" tabindex="-1"></a>  fcast<span class="ot">&lt;-</span><span class="fu">forecast</span>(fit, <span class="at">h =</span> h)</span>
<span id="cb44-13"><a href="#cb44-13" aria-hidden="true" tabindex="-1"></a>  mapeAlisado[i <span class="sc">+</span> <span class="dv">1</span>,] <span class="ot">&lt;-</span> <span class="dv">100</span><span class="sc">*</span><span class="fu">abs</span>(test.set <span class="sc">-</span> fcast<span class="sc">$</span>mean)<span class="sc">/</span>test.set</span>
<span id="cb44-14"><a href="#cb44-14" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb44-15"><a href="#cb44-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-16"><a href="#cb44-16" aria-hidden="true" tabindex="-1"></a>errorAlisado <span class="ot">&lt;-</span> <span class="fu">colMeans</span>(mapeAlisado)</span>
<span id="cb44-17"><a href="#cb44-17" aria-hidden="true" tabindex="-1"></a>errorAlisado</span></code></pre></div>
<pre><code> [1] 1.921557 2.155027 2.289600 2.665644 2.700566 2.740968 2.879119 2.907797
 [9] 3.028863 3.155796 3.219962 3.502559</code></pre>
<div class="sourceCode" id="cb46"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">x =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">12</span>, <span class="at">y =</span> errorAlisado)) <span class="sc">+</span></span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;Figura 12. Error de predicción según horizonte temporal&quot;</span>) <span class="sc">+</span></span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">&quot;Horizonte temporal de predicción&quot;</span>) <span class="sc">+</span></span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">&quot;MAPE&quot;</span>) <span class="sc">+</span></span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="at">breaks=</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">12</span>)</span></code></pre></div>
<p><img src="03-05-Tema5_files/figure-html/unnamed-chunk-33-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>La figura 12 muestra el error de previsión extra-muestral según el horizonte temporal. El error extra-muestral a un periodo vista es comparable al error intra-muestral (1.9% frente a 1.8%). Aunque el error de previsión aumenta conforme lo hace el horizonte temporal, siempre se mantiene muy bajo. Por ejemplo, en las previsiones a 12 meses vista el error es del 3.5%.</p>
<p><br />
</p>
</div>
</div>
<div id="otras-alternativas-para-predecir-nacimientos" class="section level2" number="10.3">
<h2 number="10.3"><span class="header-section-number">10.3</span> Otras alternativas para predecir Nacimientos</h2>
<p>A la hora de predecir hay que ser un poco imaginativos, dedicarle tiempo y probar cosas. Por ejemplo, podríamos predecir los nacimientos a partir del ajuste de la transformación logarítmica. O podemos probar a cambiar el criterio de estimación de los parámetros o el de selección del modelo óptimo.</p>
<p>Yendo un poco más lejos, y dado que el número de nacimientos depende forzosamente del número de días del mes, podemos predecir los nacimientos medios por día (cociente entre los nacimientos de cada mes y el número de días del mes). Esta serie tendrá una componente estacional más suave, elimina el efecto de los meses de febrero bisiestos y tendrá, previsiblemente, un mejor ajuste.</p>
<p>También podemos mezclar varios de los enfoques previos o ser aún más imaginativos.</p>
<p>El siguiente código muestra el MAPE (para previsiones intra-muestrales a un periodo vista) para varias de estas opciones. Puedes deducir que se está haciendo en cada caso a partir del código. Sería más adecuado usar otro criterio de validación diferente, pero el objetivo de este epígrafe es recalcar que no hay que quedarse con lo inmediato (predecir Nacimientos con las opciones por defecto de las funciones), sino probar y probar.</p>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Serie Nacimientos</span></span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a><span class="fu">accuracy</span>(<span class="fu">ets</span>(nacimientosb, </span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a>             <span class="at">damped =</span> <span class="cn">FALSE</span>))[<span class="dv">5</span>]</span></code></pre></div>
<pre><code>[1] 1.751808</code></pre>
<div class="sourceCode" id="cb49"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="fu">accuracy</span>(<span class="fu">ets</span>(nacimientosb, </span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>             <span class="at">damped =</span> <span class="cn">FALSE</span>, </span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a>             <span class="at">opt.crit =</span> <span class="st">&quot;mse&quot;</span>))[<span class="dv">5</span>]</span></code></pre></div>
<pre><code>[1] 1.757418</code></pre>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Transformación logarítmica</span></span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a><span class="fu">accuracy</span>(<span class="fu">ets</span>(nacimientosb, </span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a>             <span class="at">lambda =</span> <span class="dv">0</span>, </span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a>             <span class="at">damped =</span> <span class="cn">FALSE</span>))[<span class="dv">5</span>]</span></code></pre></div>
<pre><code>[1] 1.773713</code></pre>
<div class="sourceCode" id="cb53"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="fu">accuracy</span>(<span class="fu">ets</span>(nacimientosb, </span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a>             <span class="at">lambda =</span> <span class="dv">0</span>, </span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a>             <span class="at">damped =</span> <span class="cn">FALSE</span>, </span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a>             <span class="at">opt.crit =</span> <span class="st">&quot;mse&quot;</span>))[<span class="dv">5</span>]</span></code></pre></div>
<pre><code>[1] 1.773713</code></pre>
<div class="sourceCode" id="cb55"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Transformación logarítmica insesgada</span></span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a><span class="fu">accuracy</span>(<span class="fu">ets</span>(nacimientosb, </span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a>             <span class="at">lambda =</span> <span class="dv">0</span>, </span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a>             <span class="at">biasadj =</span> <span class="cn">TRUE</span>,</span>
<span id="cb55-5"><a href="#cb55-5" aria-hidden="true" tabindex="-1"></a>             <span class="at">damped =</span> <span class="cn">FALSE</span>))[<span class="dv">5</span>]</span></code></pre></div>
<pre><code>[1] 1.773726</code></pre>
<div class="sourceCode" id="cb57"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="fu">accuracy</span>(<span class="fu">ets</span>(nacimientosb, </span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a>             <span class="at">lambda =</span> <span class="dv">0</span>, </span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a>             <span class="at">biasadj =</span> <span class="cn">TRUE</span>,</span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true" tabindex="-1"></a>             <span class="at">damped =</span> <span class="cn">FALSE</span>, </span>
<span id="cb57-5"><a href="#cb57-5" aria-hidden="true" tabindex="-1"></a>             <span class="at">opt.crit =</span> <span class="st">&quot;mse&quot;</span>))[<span class="dv">5</span>]</span></code></pre></div>
<pre><code>[1] 1.773726</code></pre>
<div class="sourceCode" id="cb59"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Nacimientos por dia</span></span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a><span class="fu">accuracy</span>(<span class="fu">ets</span>(nacimientosb<span class="sc">/</span><span class="fu">monthdays</span>(nacimientosb), </span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a>             <span class="at">damped =</span> <span class="cn">FALSE</span>))[<span class="dv">5</span>]</span></code></pre></div>
<pre><code>[1] 1.677256</code></pre>
<div class="sourceCode" id="cb61"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="fu">accuracy</span>(<span class="fu">ets</span>(nacimientosb<span class="sc">/</span><span class="fu">monthdays</span>(nacimientosb), </span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a>             <span class="at">damped =</span> <span class="cn">FALSE</span>, </span>
<span id="cb61-3"><a href="#cb61-3" aria-hidden="true" tabindex="-1"></a>             <span class="at">opt.crit =</span> <span class="st">&quot;mse&quot;</span>))[<span class="dv">5</span>]</span></code></pre></div>
<pre><code>[1] 1.671269</code></pre>
<p>La principal conclusión en este caso es que salirse de la estimación directa sobre la serie original no reduce el error significativamente. Sin embargo, cabe destacar que,</p>
<ul>
<li>El error de estimación de los nacimientos por día es menor, al tratarse de una serie con mejor comportamiento, aunque la ganancia no es mucha. (Véanse los dos últimos modelos respecto de los dos primeros)</li>
<li>Usar la transformación logarítmica (con o sin predicciones insesgadas) no mejora la capacidad predictiva del modelo. (Véanse los modelos 3 a 6 respecto de los modelos 1 y 2)</li>
<li>El mejor modelo estima los nacimientos por día y estima los parámetros minimizando el error cuadrático medio (“mse”). Todo menos lo <em>directo</em>.</li>
</ul>
<p><br />
<br />
</p>
</div>
</div>
<div id="resumen-de-los-comandos-utilizados" class="section level1" number="11">
<h1 number="11"><span class="header-section-number">11</span> Resumen de los comandos utilizados</h1>
<table>
<colgroup>
<col width="18%" />
<col width="14%" />
<col width="66%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Función</th>
<th align="left">Paquete</th>
<th align="left">Descripción</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><code>ses</code></td>
<td align="left">forecast</td>
<td align="left">Estimación del modelo de alisado exponencial simple</td>
</tr>
<tr class="even">
<td align="left"><code>holt</code></td>
<td align="left">forecast</td>
<td align="left">Estimación del modelo de alisado exponencial de Holt</td>
</tr>
<tr class="odd">
<td align="left"><code>hw</code></td>
<td align="left">forecast</td>
<td align="left">Estimación del modelo de alisado exponencial de Holt-Winters</td>
</tr>
<tr class="even">
<td align="left"><code>ets</code></td>
<td align="left">forecast</td>
<td align="left">Estimación de una amplia familia de métodos de alisado exponencial</td>
</tr>
<tr class="odd">
<td align="left"><code>residuals</code></td>
<td align="left">stats</td>
<td align="left">Obtiene el residuo de un modelo estimado</td>
</tr>
</tbody>
</table>
<p><br />
<br />
</p>
</div>
<div id="referencias" class="section level1" number="12">
<h1 number="12"><span class="header-section-number">12</span> Referencias</h1>
<ul>
<li><p>Brown, R. G. (1959). <em>Statistical forecasting for inventory control</em>. Ed. McGraw/Hill.</p></li>
<li><p>Gardner, Jr, E. S. y McKenzie, E. (1985) <em>Forecasting trends in time series</em>, Management Science, 31(10), pp. 1237–1246. <a href="doi:10.1287/mnsc.31.10.1237" class="uri">doi:10.1287/mnsc.31.10.1237</a></p></li>
<li><p>Holt, C. E. (1957). <em>Forecasting seasonals and trends by exponentially weighted averages</em> O.N.R. Memorandum No. 52. Carnegie Institute of Technology, Pittsburgh USA. <a href="doi:10.1016/j.ijforecast.2003.09.015" class="uri">doi:10.1016/j.ijforecast.2003.09.015</a></p></li>
<li><p>Hyndman, R. J. y Khandakar, Y. (2008) <em>Automatic Time Series Forecasting: The forecast Package for R</em>. Journal of Statistical Software, 27(3), pp. 1-22. <a href="doi:10.18637/jss.v027.i03" class="uri">doi:10.18637/jss.v027.i03</a></p></li>
<li><p>Hyndman, R. J., Koehler, A., B., Ord, J. K. y Snyder, R. D. (2008) <em>Forecasting with Exponential Smoothing: the State Space Approach</em>. Ed. Springer.</p></li>
<li><p>Winters, P. R. (1960). <em>Forecasting sales by exponentially weighted moving averages</em>. Management Science, 6, pp. 324–342. <a href="doi:10.1287/mnsc.6.3.324" class="uri">doi:10.1287/mnsc.6.3.324</a></p></li>
</ul>
<p><br />
<br />
<br />
<br />
</p>
</div>

<div id="rmd-source-code">---
title: "Técnicas de Alisado Exponencial"
subtitle: "Previsión con Datos Temporales (GBIA)"
author: "Iván Arribas (Depto. Análisis Económico. Universitat de València)"
output: 
  html_document:
    code_download: yes
    df_print: kable
    fig_caption: no
    highlight: pygments
    number_sections: yes
    self_contained: yes
    theme: cerulean
    toc: yes
    toc_depth: 2
    toc_float:
      collapsed: yes
---

```{r chunk_setup, echo = FALSE}
knitr::opts_chunk$set(warning = FALSE, 
                      message = FALSE, 
                      comment = "",
                      fig.align = "center", 
                      fig.show = "hold",
                      fig.height = 4,
                      fig.width = 8,
                      out.width = "80%") 
```

```{r options_setup, echo = FALSE}
options(scipen = 999) #- para quitar la notacion cientifica
```

```{r librerias, echo = FALSE}
library(forecast)
library(ggplot2); theme_set(theme_bw())
library(gridExtra)
library(grid)
```

\
\

# Introducción

Los métodos de alisado exponencial aparecen en los años 50 de la mano de Brown, Holt y Winters y han sido la raíz de uno de los métodos de predicción más sencillos y eficaces. La idea básica es predecir usando una media ponderada de los datos pasados, donde los más recientes tienen un peso mayor y este decae exponencialmente conforme usamos observaciones más antiguas.

El alisado exponencial es una familia de métodos de ajuste y previsión que ofrece muy buenos resultados para predicciones a corto plazo o para predecir series con pocos datos o _sencillas_ (sin mucho _ruido_).

Suponen un grado de modelización mayor que los métodos sencillos vistos previamente, pero sin alcanzar la complejidad de otras metodologías (modelos ARIMA).  

En origen, son métodos descriptivos con el único objetivo de producir __predicciones puntuales__. Sin embargo, su enfoque como modelos de _espacio de estados_ posibilita un marco teórico para obtener __intervalos de predicción__.

\
\

# Componentes de una serie en el contexto del alisado exponencial

Para obtener una predicción en el periodo $t+1$ con datos hasta el periodo $t$ necesitamos tres componentes:

* La estimación del nivel de la serie en el periodo $t$: $l_t$
* La estimación de la pendiente de la serie en el periodo $t$: $b_t$
* La estimación de la estacionalidad en el mes correspondiente al periodo $t+1$ con datos hasta $t$: $s_{t + 1 - m}$ (recuerda, $m$ es el orden estacional

A partir de estas componentes, obtenidas en el periodo $t$ y para un esquema aditivo, se tendría que la predicción en el periodo $t+1$ es:
$$\widehat{y}_{t+1} = l_t+b_t+s_{t+1-m}.$$
En general, las componentes pueden __existir o no__ y se pueden combinar entre ellas __aditiva o multiplicativamente__. Veamos algunos casos:

* Existen todas y son multiplicativas:
$$\widehat{y}_{t+1}=l_t \cdot b_t \cdot s_{t + 1 - m}$$
* Existen todas, nivel y pendiente aditivas, y estacionalidad multiplicativa:
$$\widehat{y}_{t+1}=(l_t+b_t)s_{t + 1 - m}$$
* No hay pendiente y la estacionalidad es aditiva:
$$\widehat{y}_{t+1}=l_t+s_{t + 1 - m}$$

¿Como obtenemos los valores de $l_t$, $b_t$ y $s_{t + 1 - m}$? Mediante __expresiones recursivas__, donde cada componente se calcula a partir de los valores hasta $t$ de la serie y de las componentes:
$$
\begin{aligned}
l_t& = f_l(y_t,y_{t-1}\ldots, l_{t-1},l_{t-2}\ldots,b_{t-1},b_{t-2}\ldots,s_{t-1},s_{t-2}\ldots) \\
b_t& = f_b(y_t,y_{t-1}\ldots, l_{t},l_{t-1}\ldots,b_{t-1},b_{t-2}\ldots,s_{t-1},s_{t-2}\ldots) \\
s_t& = f_s(y_t,y_{t-1}\ldots, l_{t},l_{t-1}\ldots,b_{t},b_{t-1}\ldots,s_{t-1},s_{t-2}\ldots)
\end{aligned}
$$
Por ejemplo, el _método ingenuo I_ se puede interpretar dentro de este contexto como un método de alisado donde $l_t = y_t$ y no hay ni pendiente ni estacionalidad. Por tanto, $\widehat{y}_{T+1} = l_{T} = y_{T}$.

De la misma forma, el _método ingenuo II_ se puede interpretar como un método de alisado donde $l_t = y_t$, $b_t = y_t - y_{t-1}$ y no hay estacionalidad. Entonces, $\widehat{y}_{T+1}=l_T + b_T = y_T + (y_T - y_{T-1})$.
    
En las expresiones previas hemos supuesto que se quería obtener una predicción a un periodo vista ($\widehat{y}_{t+1}$). Si el objetivo es estimar una previsión $h$ periodos hacia delante desde el periodo $t$, $\widehat{y}_{t+h}$, hay que modificar la ecuación de predicción adecuadamente. Por ejemplo, para el caso aditivo se tendría que 
$$\widehat{y}_{t+h} = l_t+hb_t+s_{t+h-m(k+1)}$$
donde $k = \lfloor (h-1)/m\rfloor$.

El concepto de componentes aquí visto no coincide con el definido en el Tema 1. Sin embargo, podemos asimilar la tendencia de una serie como la suma (multiplicación) del nivel y la pendiente $T_{t+1} = l_t + b_t$ ($T_{t+1} = l_t \cdot b_t$) y de esta forma ambas definiciones de componentes de una serie se hacen compatibles.

\
\

# Casos posibles

Todas las series tiene nivel, pero dependiendo del tipo de pendiente y estacionalidad hay 15 casos posibles, mostrados en la tabla siguiente.

|    Tendencia          |           | Estacionalidad |                  |
|:----------------------|:---------:|:--------------:|:----------------:|
|                       | Ninguna (N) | Aditiva (A) | Multiplicativa (M)        |
| Ninguna (N)           |__N, N__   |       N, A     |        N, M      |
| Aditiva (A)           |__A, N__   |   __A, A__     |    __A, M__      |
| Aditiva Amortiguada (Ad)  |__Ad, N__  |      Ad, A     |       Ad, M      |
| Multiplicativa (M)    |    M, N   |       M, A     |        M, M      |
| Multiplicativa Amortiguada (Md) |    Md, N  |      Md, A     |       Md, M      |


Cada caso difiere en las componentes que se observan y su esquema, dando lugar a un conjunto diferente de ecuaciones recursivas de actualización.

Si se añade que el error puede ser aditivo o multiplicativo, da 30 posibilidades. El tipo de error (aditivo o multiplicativo) no afecta ni a la estimación ni a la previsión puntual, sólo es relevante en el cálculo del intervalo de confianza de las predicciones.

Los modelos más usuales son:

* (N, N):   Alisado exponencial simple
* (A, N):   Alisado de Holt
* (Ad, N):  Alisado con tendencia amortiguada (d de _damped_)
* (A, A):   Alisado de Holt-Winters aditivo
* (A, M):   Alisado de Holt-Winters multiplicativo

Acude al artículo de [Rob J. Hyndman y Yeasmin Khandakar (2008)](http://www.jstatsoft.org/v27/i03/paper) para saber más de cada modelo, o al libro _Forecasting with Exponential Smoothing: the State Space Approach_ (2008) de Hyndman y otros autores.

\
\

# Alisado exponencial simple (N, N)

\

## Definición

El alisado exponencial simple es adecuado para una serie estacionaria y sin estacionalidad. Es decir, una serie que se mueve alrededor de un nivel constante.

La ecuación de la __predicción intra-muestral__ es 
$$\widehat{y}_{t+1} = \alpha y_t + \alpha (1-\alpha) y_{t-1} + \alpha (1-\alpha)^2 y_{t-2} + \alpha (1-\alpha)^3 y_{t-3} + \ldots =  \alpha y_t + (1-\alpha)\widehat{y}_{t},$$
donde $0 \leq \alpha \leq 1$ es el parámetro de suavizado. La primera __predicción extra-muestral__ queda 
$$\widehat{y}_{T+1}=\alpha y_T + (1-\alpha)\widehat{y}_{T}$$
y para las restantes
$$\widehat{y}_{T+h} = \widehat{y}_{T+1}.$$
\

## Formulas interactivas de sus componentes

En el alisado exponencial simple solo hay una componente, el nivel $l_t$.

* La __ecuación recursiva__ de suavizado es $l_t=\alpha y_t + (1-\alpha)l_{t-1}$
* La ecuación de __predicción intra-muestral__ es $\widehat{y}_{t+1} = l_t$
* La ecuación de __predicción extra-muestral__ es $\widehat{y}_{T+h} = \widehat{y}_{T+1} = l_T$

Dos estimaciones razonables de $l_t$, el nivel de la serie en el periodo $t$, son el valor observado para la serie en ese periodo $y_t$ y el nivel del periodo previo $l_{t-1}$. La estimación final de $l_t$ es una media ponderada de ambas y esta estimación final es la previsión de la serie para el periodo siguiente. 

\

## Estimación de los parámetros del modelo
    
Dado el proceso iterativo para el cálculo de $l_t$ se necesita un __valor inicial__ de arranque $l_0$. Cada programa estadístico usa su propio método para obtener $l_0$.
    
Respecto de $\alpha$, usualmente se estima el valor __optimo__ según un criterio de precisión de la predicción. El parámetro $\alpha$ __se puede interpretar__ como:

* Si $\alpha = 1$ se tiene el _método ingenuo I_ ($\widehat{y}_{t+1}=y_t$), óptimo cuando el nivel de la serie varía constantemente en el tiempo.
* Si $\alpha = 0$ se tiene $\widehat{y}_{t} =l_0$, óptimo cuando el nivel permanece constante en el tiempo.

\

## Ejemplo

Vamos a usar el método de alisado exponencial simple para predecir la serie Libros. Usaremos para ello la función `ses` (_simple exponential smoothing_) con una previsión a 5 años vista (`h = 5`). Esta función estima los valores de $l_0$ y $\alpha$ que maximizan la función de verosimilitud, pero se pueden elegir otros criterios con el parámetro `opt.crit`.

```{r}
libros <- read.csv2("./series/libros.csv", header = TRUE)
libros <- ts(libros[, 2], start = 1993, frequency  = 1)


librosf <- ses(libros, h = 5, level = 95)
summary(librosf)
```

Veamos la salida en detalle:

* El valor de $\alpha$ que optimiza el criterio usado para medir la calidad del ajuste es $\alpha =$ `r round(librosf$model$par[1],2)`, un valor muy cercano a 1. Esto es un indicativo de que: i) la serie Libros cambia de nivel de forma constante, un rasgo en los procesos puramente estocásticos como el paseo aleatorio; y ii) el método de alisado exponencial simple se aproxima al método Ingenuo I. 
* El valor de arranque $l_0$ óptimo es `r round(librosf$model$par[2],2)`. 
* _sigma_ es la desviación típica del error (aditivo) de predicción. Se diferencia de RMSE en el denominador. Para calcular _sigma_ en lugar de dividir por $T$ se divide por $T$ menos el número de parámetros estimados (en este caso 3, $l_0$, $\alpha$ y _sigma_).
* La calidad del ajuste es razonable, como evidencia el error porcentual medio del 7%.
* Las predicciones son las mismas para los 5 años, como cabe esperar (recuerda que $\widehat{y}_{T+h} = l_T$).

```{r}
tail(librosf$model$states, n = 4)
```

En el objeto `librosf` la matriz `librosf$model$states` guarda todos los valores del nivel obtenidos con la ecuación recursiva, incluidos el valor de arranque, así que es una matriz con $T+1$ filas. Puedes ver el valor de $l_{2018}$ en su última fila, que vale `r formatC(librosf$model$states[27,], format = "f", digits = 2)`. Así, la predicción para $2019$ es $\widehat{y}_{2019}=l_{2018}=$ `r formatC(librosf$model$states[27,], format = "f", digits = 2)`. Igualmente $\widehat{y}_{2020}=l_{2018}=$ `r formatC(librosf$model$states[27,], format = "f", digits = 2)`. Es decir, todas las previsiones son iguales a $l_{2018}$.


La figura 1 muestra la serie Libros, las previsiones extra-muestrales que son constantes y el intervalo de confianza. Conforme aumentamos el horizonte de predicción, el intervalo de confianza es más amplio como reflejo de la mayor incertidumbre en la predicción.
 
```{r}
autoplot(librosf,
         xlab = "",
         ylab = "Títulos",
         main = "Figura 1. Libros y predicción con alisado simple")
```


\
\

# Alisado exponencial de Holt (A, N)

El alisado exponencial de Holt es adecuado para una serie no estacionaria y sin estacionalidad.

\

## Formulas interactivas de sus componentes

Las __ecuaciones recursivas__ son
$$
\begin{aligned}
l_t & =\alpha y_t + (1-\alpha)(l_{t-1}+b_{t-1}) \\
b_t & =\beta (l_t - l_{t-1}) + (1-\beta)b_{t-1} 
\end{aligned}
$$
La ecuación de la __predicción intra-muestral__ a un periodo vista es
$$\widehat{y}_{t+1} = l_t + b_t,$$
\noindent de forma que la ecuación de __predicción extra-muestral__ es 
$$\widehat{y}_{T+h}=l_T + h b_T.$$ 
 
Dos estimaciones razonables del nivel de la serie en el periodo $t$ son el valor observado para la serie en ese periodo $y_t$, y una estimación del nivel del periodo $t$ realizada desde el periodo $t-1$: $l_{t-1} + b_{t-1}$. Por otro lado, dos estimaciones razonables de la pendiente de la serie en el periodo $t$ son el cambio de nivel de $t-1$ a $t$ (el último observado) $l_t-l_{t-1}$, y el valor de la pendiente en el periodo previo, $b_{t-1}$. En ambos casos, nivel y pendiente, la estimación final es una media ponderada, parametrizada por $0 \leq \alpha, \: \beta \leq 1$.

\

## Estimación de los parámetros del modelo

Para aplicar este método es necesario estimar unos valores iniciales $l_0$ y $b_0$ de las ecuaciones recursivas e identificar los valores más adecuados de los parámetros $\alpha$ y $\beta$. Los __valores óptimos__ de estos cuatro parámetros se obtienen optimizando una medida de precisión de las predicciones.

La interpretación del parámetro $\alpha$ es similar al caso del alisado exponencial simple.

__Interpretación del parámetro $\beta$__:

* Si $\beta = 1$, $b_t  = l_t - l_{t-1}$, la pendiente se actualiza constantemente porque varía periodo a periodo Puede ser un indicador de mal ajuste (tendencia no lineal o pendiente no aditiva).
* Si $\beta = 0$, $b_t = b_{t-1}= \ldots = b_0$, la pendiente se mantiene constante en el tiempo.

El _método ingenuo II_ es un caso concreto de Alisado de Holt. Si hacemos $\alpha=\beta = 1$, queda $l_t=y_t$ y $b_t=y_t-y_{t-1}$, por tanto
$$\widehat{y}_{T+h}=l_T + h \cdot b_T = y_T + h(y_T - y_{T-1}).$$

\

## Ejemplo

Vamos a usar el método de alisado de Holt para predecir de nuevo la serie Libros. Usaremos para ello la función `holt` con una previsión a 5 años vista (`h = 5`).

```{r}
librosf <- holt(libros, h = 5, level = 95)
summary(librosf)
```

Los valores óptimos de los cuatro parámetros son $\alpha=$ `r round(librosf$model$par[1],2)`, $\beta=$ `r round(librosf$model$par[2],2)`, $l_0 =$ `r round(librosf$model$par[3],2)` y $b_0 =$ `r round(librosf$model$par[4],2)`. Observa que $\alpha$ es prácticamente 1 y que $\beta$ es cero. Si aplicamos estos valores de los parámetros a las ecuaciones recursivas y la predicción extra-muestral, obtenemos $y_{T+h}=y_T + hb_0$: la predicción es el último valor observado más $h$ veces la primera pendiente estimada.

La calidad de las predicciones es razonable, con un error porcentual medio del 6.7%, y se ha mejorado respecto del alisado exponencial simple.

```{r}
tail(librosf$model$states, n = 4)
```

De nuevo, en el objeto `librosf` la matriz `librosf$model$states` guarda todos los valores obtenidos con las ecuaciones recursivas, en este caso el nivel y la pendiente, incluidos los valores de arranque. Puedes ver los valores de $l_{2018}$ y $b_{2018}$ en su última fila, que valen respectivamente `r formatC(librosf$model$states[27,], format = "f", digits = 2)`. Así, la predicción para $2019$ es $\widehat{y}_{2019}=l_{2018} + b_{2018}=$ `r formatC(librosf$model$states[27, 1], format = "f", digits = 2)` $+$ `r formatC(librosf$model$states[27, 2], format = "f", digits = 2)` $=$ `r formatC(sum(librosf$model$states[27,]), format = "f", digits = 2)`. Igualmente $\widehat{y}_{2020}=l_{2018} + 2\cdot b_{2018}=$ `r formatC(librosf$model$states[27,1] + 2* librosf$model$states[27,2], format = "f", digits = 2)`. Es decir, el incremento entre previsiones es contante e igual a $b_{2018}$ que, por ser $\beta$ prácticamente nulo, coincide con $b_0$.

La figura 2 muestra la serie Libros y las previsiones extra-muestrales que muestran una ligera tendencia creciente.
 
```{r}
autoplot(librosf,
         xlab = "",
         ylab = "Títulos",
         main = "Figura 2. Libros y predicción con alisado de Holt")
```

\
\

# Alisado exponencial con pendiente amortiguada (Ad, N)

Las previsiones con el método de Holt presentan siempre una pendiente constante. En previsiones a corto plazo esto no es un problema, pero para previsiones a largo plazo la experiencia indica que suele aparecer un sesgo de previsión. El alisado exponencial con pendiente amortiguada trata de corregir esta limitación. El mecanismo, propuesto por Gardner y McKenzie en 1985, es introducir un nuevo parámetro $0 \leq \phi \leq 1$ que _amortigua_ la tendencia hasta hacerla plana en el largo plazo.

\

## Formulas interactivas de sus componentes

Las __ecuaciones recursivas__ son
$$
\begin{aligned}
l_t & =\alpha y_t + (1-\alpha)(l_{t-1}+\phi b_{t-1}) \\
b_t & =\beta (l_t - l_{t-1}) + (1-\beta)\phi b_{t-1} 
\end{aligned}
$$

La ecuación de la __predicción intra-muestral__ a un periodo vista es
$$\widehat{y}_{t+1} = l_t + \phi b_t,$$
\noindent de forma que la ecuación de __predicción extra-muestral__ es 
$$\widehat{y}_{T+h}=l_T + (\phi + \phi^2 + \ldots + \phi^h) b_T.$$ 
 
Si $\phi = 1$, se tiene el alisado de Holt y si $\phi = 0$, se tiene el alisado simple. Para valores entre $0$ y $1$ en el corto plazo las predicciones tienen pendiente y en el largo plazo se hacen constantes e iguales a $l_T + \phi b_T/(1 - \phi)$.

\

## Ejemplo

Vamos a usar el método de alisado con amortiguamiento para predecir, una vez más, la serie Libros añadiendo a la función `holt` el argumento `damped = TRUE`. Por razones prácticas el rango de búsqueda de $\phi$ queda en el intervalo $[0.8, 0.98]$. En este caso, para ver el efecto del _amortiguamiento_ vamos a fijar el valor de $\phi$ a $0.9$ y vamos a pedir un horizonte temporal más largo.

```{r}
librosfd <- holt(libros, damped = TRUE, h = 15, phi = 0.9)
summary(librosfd)
```

La figura 3 muestra la serie Libros, su estimación (intra-muestral) y las predicciones a 15 años vista. Observa que la pendiente de las previsiones se _amortigua_ en el tiempo, de forma que al principio las previsiones crecen más rápidamente que en los últimos años.
 
```{r}
autoplot(librosfd,
         xlab = "",
         ylab = "Títulos",
         main = "Figura 3. Libros y predicción con alisado exponencial con amortiguamiento",
         PI = FALSE)
```

\
\

# Alisado de Holt-Winters aditivo (A, A) y multiplicativo (A, M)

El método de alisado exponencial de Holt-Winters es adecuado para una serie con tendencia y con estacionalidad. Existen dos versiones según que el esquema sea aditivo o multiplicativo.

\

## Alisado de Holt-Winters aditivo (A, A)

Las __ecuaciones recursivas__ de actualización son:
$$
\begin{aligned}
l_t & =\alpha (y_t - s_{t-m} ) + (1-\alpha)(l_{t-1}+b_{t-1}) \\
b_t & =\beta (l_t - l_{t-1}) + (1-\beta)b_{t-1} \\
s_t & =\gamma (y_t - l_{t-1} - b_{t-1}) + (1 - \gamma)s_{t-m}
\end{aligned}
$$
con $0 \leq \alpha, \beta, \gamma \leq 1$.

La ecuación de la __predicción intra-muestral__ a un periodo vista es 
$$\widehat{y}_{t+1}  = l_t + b_t + s_{t+1-m},$$
\noindent de forma que la ecuación de __predicción extra-muestral es__:
$$\widehat{y}_{T+h}=l_T + h b_T + s_{T+h - m(k+1)},$$ 
\noindent con $k = \lfloor(h-1)/m\rfloor$.

\

## Alisado de Holt-Winters multiplicativo (A, M)

Las __ecuaciones recursivas__ de actualización son:
$$
\begin{aligned}
l_t & =\alpha \frac{y_t}{s_{t-m}} + (1-\alpha)(l_{t-1}+b_{t-1}) \\
b_t & =\beta (l_t - l_{t-1}) + (1-\beta)b_{t-1} \\
s_t & =\gamma \frac{y_t}{l_{t-1} + b_{t-1}} + (1 - \gamma)s_{t-m}
\end{aligned}
$$

La ecuación de la __predicción intra-muestral__ a un periodo vista es 
$$\widehat{y}_{t+1}  = (l_t + b_t)s_{t+1-m},$$
de forma que la ecuación de __predicción extra-muestral es__:
$$\widehat{y}_{T+h}=(l_T + h b_T)s_{T+h - m(k+1)}.$$ 

\

## Ejemplo

Vamos a usar el método de Holt-Winters para predecir la serie Nacimientos, que presentaba un esquema multiplicativo. Para ello usaremos la función `hw` con el argumento `seasonal = "multiplicative"` (que sería `seasonal = "additive"` en caso de esquema aditivo). Vamos a considerar la serie Nacimientos desde enero de 2000 y pedir una previsión a dos años vista.

```{r}
nacimientos <- read.csv2("./series/nacimientos.csv", header = TRUE)
nacimientos <- ts(nacimientos[, 2],
                  start = c(1975, 1),
                  frequency = 12)

nacimientosb <- window(nacimientos, start = 2000)
nacimientosbf <- hw(nacimientosb, seasonal = "mult", h = 24)
summary(nacimientosbf)
```

Los valores óptimos de los parámetros son $\alpha=$ `r round(nacimientosbf$model$par[1],2)`, $\beta=$ `r round(nacimientosbf$model$par[2],2)` y $\gamma=$ `r round(nacimientosbf$model$par[3],2)`. Los valores tan bajos para $\beta$ y $\gamma$ indican que ambas, la pendiente y la estacionalidad, modifican su valor muy lentamente. Es decir, hay pendiente y hay efecto estacional, pero varían muy lentamente en el tiempo.

La calidad de las predicciones es notable, con un error porcentual medio del 1.8%. Recuerda que con el método ingenuo con estacionalidad el error era del 3.6%.

Los últimos valores de las componentes son 
```{r, eval = FALSE}
TT <- nrow(nacimientosbf$model$states)
nacimientosbf$model$states[TT,]
```

```{r, echo = FALSE}
TT <- nrow(nacimientosbf$model$states)
round(nacimientosbf$model$states[TT,], 3)
```

Como el último dato de la serie es diciembre de 2018, los valores del nivel $l$ y la pendiente $b$ mostrados corresponden a ese periodo. Sin embargo, la componente estacional tiene un orden muy peculiar: s1 es el valor estacional para diciembre (mes del último dato), s2 el de noviembre, s3 de octubre, hasta s11 que sería febrero y s12 que es enero. Podemos reproducir las predicciones para los primeros 12 meses de enero a febrero con (ojo, el etiquetado de la salida no es correcto):

```{r}
(nacimientosbf$model$states[TT, 1] + (1:12)*nacimientosbf$model$states[TT, 2]) * 
  nacimientosbf$model$states[TT, 14:3]
```

La figura 4 muestra la serie Nacimientos y las previsiones extra-muestrales.
 
```{r}
autoplot(nacimientosbf,
         xlab = "",
         ylab = "Nacimientos",
         main = "Figura 4. Nacimientos y predicción con alisado de Holt-Winters multiplicativo",
         PI = FALSE)
```

\
\

# Ejemplo con transformación logarítmica

Una alternativa a predecir la serie Nacimientos, que tiene esquema multiplicativo, es predecir la transformación logarítmica de la serie, que tendrá un esquema aditivo. Después, se aplica la transformación inversa y se obtienen las predicciones de la serie original.

Este proceso se puede realizar de forma sencilla y transparente con cualquiera de las funciones de alisado exponencial que hemos visto a partir de los argumentos `lambda` y `biasadj`.

* `lambda = 0` indica a la función de alisado que se ha de realizar la transformación logarítmica de la serie. Es un parámetro de la transformación Box-Cox que comentaremos en el tema 6. 
* `biasadj = TRUE` es necesario si tras una transformación de la serie original queremos que las predicciones sean insesgadas. Sea $y_t$ la serie original y $z_t=log(y_t)$ su transformación logarítmica. Si obtenemos una predicción $\widehat{y}_t$ de la serie original, esta será insesgada $E[\widehat{y}_t]=y_t$. Ahora bien, si obtenemos una predicción $\widehat{z}_t$ de la serie transformada, podemos pensar que $e^{\widehat{z}_t}$ es una predicción insesgada de la serie original, pero resulta que $E[e^{\widehat{z}_t}] \neq y_t$. Es decir, la exponencial de la predicción de la serie con transformada logarítmica no es insesgada. Si el argumento `biasadj` es fijado a FALSE, las predicciones se calcularán de forma directa deshaciendo la transformación y serán sesgadas; si es fijado a TRUE, las predicciones se calcularán por medio de una fórmula alternativa y serán insesgadas. En ambos casos las estimaciones son consistentes, así que para series largas no debería observarse mucha diferencia entre las dos alternativas.

Vamos a practicar el uso de estos argumentos con la serie Nacimientos. Como se va a predecir el logaritmo de la serie, se debe indicar a la función `hw` que use el modelo Holt-Winters aditivo.

```{r}
nacimientosbfl <- hw(nacimientosb, 
                     seasonal = "addit", 
                     h = 24, 
                     lambda = 0, 
                     biasadj = TRUE)
summary(nacimientosbfl)
```

Observa que en este caso la calidad de las predicciones (MAPE = 1.9%) es inferior a la obtenida con la serie sin transformar.

La figura 5 muestra la serie Nacimientos y las previsiones extra-muestrales obtenidas con y sin la transformación logarítmica.
 
```{r, echo = FALSE}
autoplot(nacimientosb,
         xlab = "",
         ylab = "Nacimientos",
         main = "Figura 5. Nacimientos y dos predicciones con alisado de Holt-Winters") + 
  autolayer(nacimientosbf, series = "Nacimientos", PI = FALSE) + 
  autolayer(nacimientosbfl, series = "Nacimientos (log)", PI = FALSE) + 
  guides(colour = guide_legend(title = "Predicción")) + 
  theme(legend.position=c(0.98,0.98), legend.justification=c(1,1)) 
```

La siguiente tabla muestra las predicciones de Nacimientos obtenidas sin transformar la serie, con transformación logarítmica y predicciones insesgadas (`biasadj = TRUE`), y con transformación logarítmica y predicciones sesgadas (`biasadj = FALSE`).

```{r, echo = FALSE}
nacimientosbfl2 <- hw(nacimientosb, seasonal = "addit", h=24, lambda = 0, biasadj = FALSE)
datos <- cbind(
  `Sin transformar` = nacimientosbf$mean,
  `log(Nac) insesgadas` = nacimientosbfl$mean,
  `log(Nac) sesgadas` = nacimientosbfl2$mean
  )
head(datos, 12)
```

Observa que las predicciones sesgadas son menores que las insesgadas. Esto siempre es así. La diferencia depende fundamentalmente de la varianza del error, _sigma_ al cuadrado en la salida de los métodos de alisado exponencial. Cuanto mayor es la varianza del error, mayores son las diferencias.

Por otro lado, las predicciones obtenidas sin y con la transformación logarítmica no guardan ninguna relación.

**Ni la transformación logarítmica ni el uso de predicciones insesgadas aseguran mejores predicciones respecto de otras opciones**, como pueden ser trabajar con predicciones sesgadas o no realizar la transformación logarítmica.

\
\

# Casos generales de alisado exponencial

En los epígrafes previos hemos visto cinco de los casos expuestos en la taxonomía del epígrafe 3, y las funciones de `R` asociadas. Veamos ahora como estimar cualquiera de los quince modelos que surgen según las diferentes posibilidades de la tendencia (N, A, Ad, M y Md) y de la estacionalidad (N, A y M). 

Recordemos que al añadir el error, aditivo o multiplicativo, estos quince modelos se convierten en treinta. Sin embargo, el tipo de error no influye en el cálculo de las previsiones, solo influye en el cálculo del intervalo de confianza de estas.

\

## La función `ets`

Podemos estimar cualquiera de los treinta modelos usando la función `ets` del paquete `forecast`. A diferencia de las funciones previas `ses`, `holt` y `hw`, la función `ets` solo estima los modelos, pero no produce predicciones. Para ello habrá que usar la función `forecast` sobre un modelo estimado con `ets`. Mira la ayuda para ver una explicación detallada de los argumentos de estas funciones.

* El tipo de modelo en `ets` se especifica con el argumento `model`, un código de tres letras indicando el tipo de Error, Tendencia y eStacionalidad (ETS). Por ejemplo, `model = "ANN"` indica un modelo con error aditivo, sin tendencia ni estacionalidad, es decir, el alisado exponencial simple; `model = "AAN"` indica un modelo con error aditivo, pendiente aditiva, pero sin estacionalidad, el alisado exponencial de Holt. El alisado exponencial de Holt-Winters multiplicativo sería `model = "AAM"`.
* Si se desea incluir amortiguamiento, hay que incluir el argumento `damped = TRUE`. 
* Por defecto `ets` no considera modelos con tendencia multiplicativa (últimas dos líneas de la taxonomía del epígrafe 3). Debes fijar el parámetro `allow.multiplicative.trend=TRUE` para contemplar esta opción.
* Además, se sigue disponiendo de los argumentos `lambda` y `biasadj`.

__Criterios de optimización__

Fijado un modelo, `ets` estima por defecto sus parámetros maximizando la función de verosimilitud. Esta búsqueda esta restringida a $0 < \beta < \alpha < 1$, $0 < \gamma < 1 - \alpha$ y $0.8 < \phi < 0.98$. Es decir, los tres primeros parámetros nunca pueden ser 0 o 1, y en la práctica sus valores límite son 0.0001 y 0.9999.

Puedes cambiar el criterio de optimización con el argumento `opt.crit`. Por defecto vale "lik", pero si lo fijas a `opt.crit = "mse"` se estiman los parámetros que minimizan el error cuadrático medio. Otra opción interesante es `opt.crit = "amse"` que minimiza la media de los errores cuadráticos medios obtenido sobre las previsiones hasta `nmse` periodos vista. En este caso usa el argumento `nmse` para fijar el valor numérico del horizonte temporal.

__Selección de modelos__

Lo más habitual es no saber cual es el mejor modelo, entendiendo como tal, el que mejor se ajusta a la serie temporal. De hecho, si lo que buscamos es predecir bien, más que entender la naturaleza del proceso generador de datos, el mejor modelo será el que mejor prediga.

Si en una de las tres letras del código del modelo se indica "Z", la función `ets` selecciona de entre los modelos posibles el que mejor se ajusta. Por ejemplo, `model = "AAZ"` indica un modelo con error y pendiente aditivos y dejaría a `ets` la búsqueda de la mejor opción para la estacionalidad (aditiva o multiplicativa). Si se especifica `model = "ZZZ` junto con `damped = NULL` (opciones por defecto) se dejaría a la función total libertad para buscar entre todos los modelos (excepto aquellos con pendiente multiplicativa). Si se desea restringir la búsqueda a modelos sin amortiguamiento basta indicar `damped = FALSE` y si se desea restringir la búsqueda solo a modelos aditivos se puede usar el argumento `additive.only = TRUE`.

Queda pendiente saber que criterio se usa para seleccionar el modelo cuando se ofrece esta opción. Esto se hace a partir de un criterio de información entre Akaike (aic), Akaike corregido para pequeñas muestras (aicc) y el Bayesiano (bic). Sus fórmulas son:
$$aic = -2log(L) + 2k$$
$$aicc = aic + \frac{k(k+1)}{T-k-1}$$
$$bic=aic + k(log(T) - 2)$$
\noindent donde $L$ es la verosimilitud, $T$ el número de datos y $k$ el de parámetros estimados (incluidos los puntos iniciales de arranque y la varianza residual).

Por defecto se usa Akaike corregido para pequeñas muestras, pero el argumento `ic` permite cambiar de criterio. 

\

## Una reflexión sobre los métodos automáticos de selección de modelos

Con el comando `forecast(ets(nacimientos), h = 24)` obtenemos una predicción mensual a dos años vista del número de nacimientos en España. Así de simple, solo 31 caracteres. Todo esto gracias a que un algoritmo interno ha estimado los parámetros de múltiples modelos, elegido el mejor modelo de todos y lo ha usado para obtener las predicciones. Podemos afirmar que tenemos las mejores predicciones. Un momento, ¿podemos?

Parémonos a reflexionar sobre lo que hemos hecho o, más bien, lo que el algoritmo ha hecho y a contrastarlo con lo que nosotros queríamos. Por un lado, el algoritmo estima los parámetros de un menú fijo de modelos y para ello usa un criterio de optimización, que por defecto es maximizar la función de verosimilitud; cuando ya tiene estimados todos los modelos, elije el mejor usando el criterio de información de Akaike corregido para muestras pequeñas; y finalmente, nosotros medimos la capacidad predictiva del modelo seleccionado usando el error absoluto porcentual medio. Vaya, resulta que en los procesos de identificación y estimación del mejor modelo se usan dos criterios diferentes, que además no coinciden con nuestro criterio de calidad de las predicciones.

Si consideramos que la calidad de un modelo viene dada por el error absoluto porcentual medio en las predicciones intra-muestrales a un periodo vista (lo que hemos decidido llamar MAPE), ¿no deberíamos estimar los parámetros del modelo usando como criterio la minimización del MAPE?, ¿no deberíamos elegir entre varios modelos aquel que presenta un MAPE menor? De esta forma, en todos los pasos del proceso se usa el mismo criterio, que es, además, el criterio que hemos considerado adecuado para valorar la calidad de las predicciones.

Pero no es esto lo que hacemos. 

Nada nos garantiza que el modelo estimado y seleccionado por el algoritmo estime las mejores predicciones posibles. Y por _mejores_ quiero decir que de entre todos los posibles modelos del menú y todos los posibles valores de sus parámetros, el seleccionado sea que el minimiza nuestro criterio de calidad de las predicciones.

Ahora ya podemos dar respuesta a la pregunta del primer párrafo: no, no podemos afirmar que nuestras predicciones sean las mejores.

Alguien dirá que casi seguro entre las predicciones sub-óptimas obtenidas por el algoritmo con su extraña mezcla de criterios y las predicciones óptimas de verdad no habrá mucha diferencia. Total, que más da una función de verosimilitud que un criterio de información que una medida del error medio. Pero lo cierto es que no lo sabemos, no tenemos ni idea de la distancia que hay entre lo óptimo y lo sub-óptimo, y si el coste de equivocarme en las predicciones es alto, puede que incluso una pequeña diferencia sea relevante.

Esta reflexión realizada en el contexto de series temporales y para la función `ets` es aplicable a todos los casos donde dejamos que un algoritmo ya programado elija el mejor modelo, y se basa en el hecho de que rara vez los criterios de estimación y elección que usan los algoritmos coinciden con el concepto de calidad de ajuste que estamos interesados

A pesar de lo aquí expuesto, como es más cómodo (y rápido) tirar de rutinas ya programadas que escribir tu propio código, seguiremos trabajando con modelos sub-óptimos y obteniendo estimaciones sub-óptimas, pero diciendo que son las mejores.

\

## Residuo aditivo versus residuo multiplicativo

En los modelos de alisado estimados por la función `ets` la fórmula para el cálculo del residuo estimado depende de su naturaleza aditiva o multiplicativa.

Si el __residuo es aditivo__, entonces el modelo es $y_t = \widehat{y}_t + \widehat{\varepsilon}_t$ y el residuo se define de la forma usual 
$$\widehat{\varepsilon}_t = y_t - \widehat{y}_t.$$
Ahora bien, si el __residuo es multiplicativo__, entonces el modelo es $y_t = \widehat{y}_t \cdot (1 + \widehat{\varepsilon}_t)$, y no $y_t = \widehat{y}_t \cdot \widehat{\varepsilon}_t$, como se podría esperar. Por tanto, el residuo multiplicativo se define como 
$$\varepsilon_t = (y_t - \widehat{y}_t)/\widehat{y}_t.$$
De esta forma en ambos casos el residuo evoluciona alrededor del valor 0 y se le pueden imponer las hipótesis usuales de ruido blanco. 

La función `residual` permite extraer de un objeto `ets` el residuo del modelo. Si el modelo tiene residuo multiplicativo y se desea obtener el residuo aditivo, se debe usar con el argumento `type = "response"`.

\
\

# Ejemplos de aplicación

\

## Libros

### Identificación y estimación del mejor modelo {-}

Si estimamos el mejor modelo de alisado exponencial para la serie Libros sin ningún tipo de restricción, nos encontramos:

```{r}
librosEts <- ets(libros)
summary(librosEts) 
```

El modelo estimado es ETS(M,N,N) o "MNN", un modelo sin pendiente ni estacionalidad y con error multiplicativo. Es decir, $y_{t+1} = l_t \cdot (1 + \varepsilon_{t+1})$. 

El valor de $\alpha$ técnicamente es 1, indicando que el nivel de la serie varia en el tiempo y que realmente estamos usando para las previsiones el método ingenuo I.

Respecto de la calidad del modelo, el valor de MAPE= $`r round(accuracy(librosEts)[5],1)`$% evidencia que estamos ante un modelo que ajusta razonablemente bien a los datos, y MASE= $`r round(accuracy(librosEts)[6],2)`$ indica que el modelo de alisado exponencial simple reduce en solo un $`r 100 - round(100*accuracy(librosEts)[6],0)`$% el error del método ingenuo I.


### Predicción {-}

Mediante la función `forecast` podemos predecir los casos de Libros. Por tratarse de un modelo sin pendiente ni estacionalidad, la predicción es constante en el tiempo (véase figura 6).

```{r}
librosEtsPre <- forecast(librosEts, h = 5)
librosEtsPre
autoplot(librosEtsPre,
         xlab = "",
         ylab = "Títulos",
         main = "Figura 6. Libros y predicción a 5 años vista")
```

### Análisis del error {-}

El error de un modelo de alisado _contiene_ la componente de __Intervención__ y el propio término de __Error__. Ver numérica o gráficamente el error permite identificar fácilmente la presencia de valores atípicos (intervención).

El modelo de alisado tiene error multiplicativo así que vamos a usar el argumento `type = "response"` para obtener el error aditivo con `residuals`.

```{r}
error <- residuals(librosEts, type = "response")
sderror <- sd(error)

autoplot(error, series="Error",
         colour = "black",
         xlab = "Periodo",
         ylab = "Error",
         main = "Figura 7: Error + Intervención") +
  geom_hline(yintercept = c(-3, -2, 2 ,3)*sderror, 
             colour = c("red", "blue", "blue", "red"), lty = 2) + 
  scale_x_continuous(breaks= seq(1993, 2019, 2)) 
```

La figura 7 muestra que aunque algún error supera las dos desviaciones típicas, ninguno puede ser considerado como claramente atípico.

### Validación: error extra-muestral a varios periodos vista {-}

Vamos a mejorar la estimación de la calidad de las predicciones obteniendo el MAPE para __previsiones extra-muestrales a varios periodos vista__. Para ello vamos a reservar, por ejemplo, las últimas 6 observaciones de la serie Libros y ajustar el modelo con las restantes. Después usaremos este modelo para calcular las predicciones a 6 periodos vista y compararlas con los valores reales de la serie Libros. 

Recuerda, este método para valorar la calidad de las predicciones usa la filosofía del método _training set/test set_: el periodo de datos usado en la estimación no se usa como periodo de datos para la validación. Sin embargo, tiene el problema de que el error obtenido es una mezcla de errores de predicción a corto, medio y largo plazo difícil de valorar. Además, los resultados dependen tremendamente del punto de corte temporal seleccionado.


```{r}
# Definimos las observaciones intra- y extra-muestrales
librosIntra <- subset(libros, end = length(libros) - 6)
librosExtra <- subset(libros, start = length(libros) - 5)

# Estimamos el modelo con todos los datos menos los 6 ultimos
librosIntraEts <- ets(librosIntra, model = "MNN")

# Predecimos los 6 años que hemos quitado de la serie y 
# vemos la calidad del ajuste.
librosExtraPre <- forecast(librosIntraEts, h = 6)
accuracy(librosExtraPre, librosExtra)
```

```{r, echo=FALSE}
error.muestral.1 <- round(accuracy(librosExtraPre, librosExtra)[1,5], 1)
error.extramuestral.n <- round(accuracy(librosExtraPre, librosExtra)[2,5],1)
```
Atendiendo al MAPE se tiene que el error de __previsión a un periodo vista__ en el __periodo intra-muestral__ de __1993 a 2012__ es del `r error.muestral.1`%; mientras que el error de __previsión a largo plazo__ en el __periodo extra-muestral__ de __2013 a 2018__ es del `r error.extramuestral.n`%. Ademas, para el periodo extra-muestral el error medio (ME) es negativo y muy elevado, un indicativo de que las previsiones están segadas. En resumen, la calidad del modelo se deteriora muy rápidamente en cuanto nos salimos de las condiciones óptimas. 

Un gráfico puede ayudar a entender este proceso de validación. En la figura 10:

* La línea de puntos vertical separa el periodo muestral (1993-2012) usado para estimar el modelo, del periodo extra-muestral (2013-2018) usado sólo para hacer las previsiones.
* La serie Libros aparece como una línea sólida en negro, desde 1993 hasta 2018.
* La previsión _intra_-muestral (a un periodo vista) de la serie Libros aparece como una línea azul.
* La línea en rojo es la previsión _extra_-muestral a largo plazo: $\hat{y}_{T+h}=l_T$, donde $T=2012$. Observa que todas las previsiones están por encima del valor real de la serie.
* Al lado de cada previsión se ha indicado el error estimado (MAPE).

Claramente estos resultados dependen del punto de corte seleccionado.

```{r,echo=FALSE}
autoplot(libros, series = "Libros",
         main="Figura 8. Libros, predicción intra- y extra-muestral",
         xlab="", 
         ylab="Títulos"
         ) +
  autolayer(fitted(librosIntraEts), series = "Libros (ajustada)") + 
  autolayer(librosExtraPre$mean, series = "Predicción") + 
  geom_vline(xintercept = 2012.5, lty = 2, col = "black") +
  scale_colour_manual(values=c("Libros"="black",
                               "Libros (ajustada)"="blue", 
                               "Predicción" = "red")) +
  guides(colour = guide_legend(title = "Series")) +
  annotate("text", x=1999, y=65000, label="7.2%", colour = "blue") +
  annotate("text", x=2016, y=72000, label="17.8%", colour = "red") +
  theme(legend.position=c(0.02,0.98), legend.justification=c(0,1)) 
```

__Nota:__ La presencia de tendencia, primero creciente y luego decreciente, en la serie Libros puede hacernos pensar que un modelo más adecuado para su ajuste y predicción sería ETS(M,A,N), forzando a que haya pendiente. De hecho, el error de estimación de este modelo es del 6%, frente al 7% para el modelo ETS(M,N,N). Sin embargo, el error de previsión extra-muestral a largo plazo para el modelo ETS(M,A,N) es del 31.5%, frente al 17.8% para el modelo ETS(M,N,N). **Mejor ajuste no implica mejor predicción.** De nuevo, incidir en que claramente estos resultados dependen del punto de corte seleccionado.

\

## Nacimientos

Veamos un segundo ejemplo con la serie Nacimientos (desde el año 2000).

### Identificación y estimación del mejor modelo {-}

Si damos total libertad al proceso de selección del mejor modelo, el óptimo tiene tendencia amortiguada con un parámetro $\phi = 0.98$, su máximo valor permitido. Este resultado aconseja repetir el proceso de selección del modelo restringido a aquellos sin amortiguamiento.

```{r}
nacimientosEts <- ets(nacimientosb, damped = FALSE)
summary(nacimientosEts) 
```

El modelo estimado es ETS(M,A,A), es decir, $y_{t+1} = (l_t + b_t +  s_{t+1-m}) \cdot (1+ \varepsilon_{t+1})$.

El bajo valor de $\beta$ y $\gamma$ indican que ambas, la pendiente y la estacionalidad, varían muy lentamente en el tiempo (véase la figura 9). 

```{r}
autoplot(nacimientosEts,
         xlab = "Periodo",
         main = "Figura 9. Componentes del modelo óptimo para Nacimientos")
```

Respecto de la calidad del modelo, el MAPE de `r round(accuracy(nacimientosEts)[5],1)`% indica que estamos ante un modelo que se ajusta muy bien a los datos; y el valor de MASE igual a `r round(accuracy(nacimientosEts)[6],2)` indica que este modelo reduce en un `r 100 - round(100*accuracy(nacimientosEts)[6],0)`% el error del método ingenuo con estacionalidad, el más sencillo posible.
      
Podemos ver los últimos valores estimados del nivel, la pendiente y la estacionalidad para interpretarlos.

```{r, eval = FALSE}
TT <- nrow(nacimientosEts$states)
nacimientosEts$states[TT,]
```

```{r, echo = FALSE}
TT <- nrow(nacimientosEts$states)
round(nacimientosEts$states[TT,],2)[1:7]
round(nacimientosEts$states[TT,],2)[8:14]
```

También podemos usarlos para predecir un año:
```{r, eval = FALSE}
nacimientosEts$states[TT, 1] + (1:12) * nacimientosEts$states[TT, 2] + 
  nacimientosEts$states[TT, 14:3]
```

```{r, echo = FALSE}
nacimientosEts$states[TT, 1] + (1:12) * nacimientosEts$states[TT, 2] + nacimientosEts$states[TT, 14:3]
```

Febrero es el mes con menor número de nacimientos: nacen `r abs(trunc(nacimientosEts$states[TT,13]))` bebés menos, respecto de la media anual. En octubre es cuando más niños nacen: `r trunc(nacimientosEts$states[TT,5])` más que la media anual.

Nuestra predicción para enero de 2019 es de `r as.integer((nacimientosEts$states[TT, 1] +  nacimientosEts$states[TT, 2]) + nacimientosEts$states[TT, 14])` bebés y para diciembre de 2019 de `r as.integer((nacimientosEts$states[TT, 1] + 12 * nacimientosEts$states[TT, 2]) + nacimientosEts$states[TT, 3])` bebés.

### Predicción {-}

Si pedimos los valores de predicción tenemos (sólo se muestran los primeros meses):
```{r, eval = FALSE}
nacimientosEtsPre <- forecast(nacimientosEts, h = 24, level = 95)
nacimientosEtsPre
```

```{r, echo = FALSE}
nacimientosEtsPre <- forecast(nacimientosEts, h = 24, level = 95)
forecast(nacimientosEts, h = 5, level = 95)
```

Gráficamente,
```{r}
autoplot(nacimientosEtsPre,
         xlab = "",
         ylab = "Bebés",
         main = "Figura 10. Nacimientos y predicción")
```

### Análisis del error {-}

El modelo de alisado tiene error multiplicativo así que debemos usar el argumento `type = "response"` para obtener el error aditivo con `residuals`.

```{r}
error <- residuals(nacimientosEts, type = "response")
sderror <- sd(error)

autoplot(error, series="Error",
         colour = "black",
         xlab = "Periodo",
         ylab = "Error",
         main = "Figura 11: Error + Intervención") +
  geom_hline(yintercept = c(-3, -2, 2 ,3)*sderror, 
             colour = c("red", "blue", "blue", "red"), lty = 2) + 
  scale_x_continuous(breaks= seq(2000, 2019, 2)) 
```

Se identifica un valor claramente atípico --supera las 4 desviaciones típicas-- que corresponde a enero de 2011. Abril de 2008 es otro candidato a intervención por alcanzar las 3 desviaciones típicas.

### Validación: error extra-muestral según horizonte temporal {-}

En este ejemplo calcularemos el error extra-muestral según el horizonte temporal de previsión, una metodología que ya hemos visto anteriormente.

```{r}  
k <- 120                 
h <- 12                  
TT <- length(nacimientosb)
s <- TT - k - h 

mapeAlisado <- matrix(NA, s + 1, h)
for (i in 0:s) {
  train.set <- subset(nacimientosb, start = i + 1, end = i + k)
  test.set <-  subset(nacimientosb, start = i + k + 1, end = i + k + h)
  
  fit <- ets(train.set, model = "MAA", damped = FALSE)
  fcast<-forecast(fit, h = h)
  mapeAlisado[i + 1,] <- 100*abs(test.set - fcast$mean)/test.set
}

errorAlisado <- colMeans(mapeAlisado)
errorAlisado

ggplot() +
  geom_line(aes(x = 1:12, y = errorAlisado)) +
  ggtitle("Figura 12. Error de predicción según horizonte temporal") +
  xlab("Horizonte temporal de predicción") +
  ylab("MAPE") +
  scale_x_continuous(breaks= 1:12)
```


La figura 12 muestra el error de previsión extra-muestral según el horizonte temporal. El error extra-muestral a un periodo vista es comparable al error intra-muestral (1.9% frente a 1.8%). Aunque el error de previsión aumenta conforme lo hace el horizonte temporal, siempre se mantiene muy bajo. Por ejemplo, en las previsiones a 12 meses vista el error es del 3.5%. 

\

## Otras alternativas para predecir Nacimientos

A la hora de predecir hay que ser un poco imaginativos, dedicarle tiempo y probar cosas. Por ejemplo, podríamos predecir los nacimientos a partir del ajuste de la transformación logarítmica. O podemos probar a cambiar el criterio de estimación de los parámetros o el de selección del modelo óptimo.

Yendo un poco más lejos, y dado que el número de nacimientos depende forzosamente del número de días del mes, podemos predecir los nacimientos medios por día (cociente entre los nacimientos de cada mes y el número de días del mes). Esta serie tendrá una componente estacional más suave, elimina el efecto de los meses de febrero bisiestos y tendrá, previsiblemente, un mejor ajuste.

También podemos mezclar varios de los enfoques previos o ser aún más imaginativos.

El siguiente código muestra el MAPE (para previsiones intra-muestrales a un periodo vista) para varias de estas opciones. Puedes deducir que se está haciendo en cada caso a partir del código. Sería más adecuado usar otro criterio de validación diferente, pero el objetivo de este epígrafe es recalcar que no hay que quedarse con lo inmediato (predecir Nacimientos con las opciones por defecto de las funciones), sino probar y probar.

```{r}
# Serie Nacimientos
accuracy(ets(nacimientosb, 
             damped = FALSE))[5]
accuracy(ets(nacimientosb, 
             damped = FALSE, 
             opt.crit = "mse"))[5]

# Transformación logarítmica
accuracy(ets(nacimientosb, 
             lambda = 0, 
             damped = FALSE))[5]
accuracy(ets(nacimientosb, 
             lambda = 0, 
             damped = FALSE, 
             opt.crit = "mse"))[5]

# Transformación logarítmica insesgada
accuracy(ets(nacimientosb, 
             lambda = 0, 
             biasadj = TRUE,
             damped = FALSE))[5]
accuracy(ets(nacimientosb, 
             lambda = 0, 
             biasadj = TRUE,
             damped = FALSE, 
             opt.crit = "mse"))[5]

# Nacimientos por dia
accuracy(ets(nacimientosb/monthdays(nacimientosb), 
             damped = FALSE))[5]
accuracy(ets(nacimientosb/monthdays(nacimientosb), 
             damped = FALSE, 
             opt.crit = "mse"))[5]
```

La principal conclusión en este caso es que salirse de la estimación directa sobre la serie original no reduce el error significativamente. Sin embargo, cabe destacar que, 

* El error de estimación de los nacimientos por día es menor, al tratarse de una serie con mejor comportamiento, aunque la ganancia no es mucha. (Véanse los dos últimos modelos respecto de los dos primeros)
* Usar la transformación logarítmica (con o sin predicciones insesgadas) no mejora la capacidad predictiva del modelo. (Véanse los modelos 3 a 6 respecto de los modelos 1 y 2)
* El mejor modelo estima los nacimientos por día y estima los parámetros minimizando el error cuadrático medio ("mse"). Todo menos lo _directo_.

\
\

# Resumen de los comandos utilizados


|Función  |Paquete | Descripción                                           |
|:--------------|:-----------|:-----------------------------------------------------|
|`ses`          |forecast  |Estimación del modelo de alisado exponencial simple|
|`holt`         |forecast   |Estimación del modelo de alisado exponencial de Holt|
|`hw`           |forecast |Estimación del modelo de alisado exponencial de Holt-Winters|
|`ets`          |forecast  |Estimación de una amplia familia de métodos de alisado exponencial|
|`residuals`    |stats   |Obtiene el residuo de un modelo estimado|

\
\

# Referencias

* Brown, R. G. (1959). _Statistical forecasting for inventory control_. Ed. McGraw/Hill.

* Gardner, Jr, E. S. y McKenzie, E. (1985) _Forecasting trends in time series_, Management Science, 31(10), pp. 1237–1246. doi:10.1287/mnsc.31.10.1237

* Holt, C. E. (1957). _Forecasting seasonals and trends by exponentially weighted averages_ O.N.R. Memorandum No. 52. Carnegie Institute of Technology, Pittsburgh USA. doi:10.1016/j.ijforecast.2003.09.015

* Hyndman, R. J. y Khandakar, Y. (2008) _Automatic Time Series Forecasting: The forecast Package for R_. Journal of Statistical Software, 27(3), pp. 1-22. doi:10.18637/jss.v027.i03

* Hyndman, R. J., Koehler, A., B., Ord, J. K. y Snyder, R. D. (2008) _Forecasting with Exponential Smoothing: the State Space Approach_. Ed. Springer.

* Winters, P. R. (1960). _Forecasting sales by exponentially weighted moving averages_. Management Science, 6, pp. 324–342.  doi:10.1287/mnsc.6.3.324

\
\
\
\
</div>
<footer class="footer">
  
<a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-sa/4.0/88x31.png" /></a>
<br>
This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.  <div class="text-muted">Website created by Iv&aacute;n Arribas. &copy;  2020. If you find any bugs please report them to <a href="mailto:ivan.arribas@uv.es"> ivan.arribas@uv.es</a>.</div>
  
</footer>




</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->
<script>
$(document).ready(function () {
  window.initializeSourceEmbed("03-05-Tema5.Rmd");
});
</script>

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
